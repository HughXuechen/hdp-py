{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.special import gammaln as logg\n",
    "\n",
    "\n",
    "def pois_fk_cust(i, x, k, Kmax, ha, hb, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "\n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "\n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + ha) - logg(ha) -\n",
    "\n",
    "                         (x[i] + ha)*np.log(1 + hb) + ha*np.log(hb) )\n",
    "\n",
    "    if new == True: return fknew_cust        \n",
    "\n",
    "    \n",
    "\n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers eating kk\n",
    "\n",
    "    xi_in = np.zeros(Kmax)                      # offset if x[i] is in this subset\n",
    "\n",
    "    xi_in[k[i]] = 1\n",
    "\n",
    "      \n",
    "\n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xi_in*x[i] + ha\n",
    "\n",
    "    bv = np.array(list(map(len, x_kks))) - xi_in + hb\n",
    "\n",
    "    fk_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + av) - logg(av) -\n",
    "\n",
    "                      (x[i] + av)*np.log(1 + bv) + av*np.log(bv) )\n",
    "\n",
    "     \n",
    "\n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pois_fk_tabl(jj, tt, x, j, t, k, Kmax, ha, hb, new=False):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the mixture components for a given table across all k values.\n",
    "\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "\n",
    "    \n",
    "\n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "\n",
    "    x_jt = x[np.logical_and(j == jj, t == tt)]\n",
    "\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "\n",
    "    \n",
    "\n",
    "    fknew_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + ha) - logg(ha) -\n",
    "\n",
    "                         (np.sum(x_jt) + ha)*np.log(len(x_jt) + hb) + ha*np.log(hb) )\n",
    "\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "\n",
    "    if len(x_jt) == 0:\n",
    "\n",
    "        #print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "\n",
    "        new = True\n",
    "\n",
    "    if new == True: return np.full(Kmax, fknew_tabl)\n",
    "\n",
    "    \n",
    "\n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers at tables serving kk\n",
    "\n",
    "    xjt_in = np.zeros(Kmax)                     # offset if table x_jt is in this subset\n",
    "\n",
    "    xjt_in[kk[0]] = 1\n",
    "\n",
    "      \n",
    "\n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xjt_in*np.sum(x_jt) + ha\n",
    "\n",
    "    bv = np.array(list(map(len, x_kks))) - xjt_in*len(x_jt) + hb\n",
    "\n",
    "    fk_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + av) - logg(av) -\n",
    "\n",
    "                       (np.sum(x_jt) + av)*np.log(len(x_jt) + bv) + av*np.log(bv) )\n",
    "\n",
    "     \n",
    "\n",
    "    return fk_tabl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mnom_fk_cust(i, x, k, Kmax, L, ha, new=False):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "\n",
    "    X can be a dense or a sparse csr-style matrix.\n",
    "\n",
    "    \n",
    "\n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    xi, ni = x[i, :], np.sum(x[i, :])\n",
    "\n",
    "    log_con = logg(ni + 1) - np.sum(logg(xi + np.ones(L))) # term constant for all k\n",
    "\n",
    "    # Calculate the case where k has no members\n",
    "\n",
    "    \n",
    "\n",
    "    if new == True:\n",
    "\n",
    "        fknew_cust = np.exp( log_con + np.sum(logg(xi + ha)) - logg(np.sum(xi + ha)) + \n",
    "\n",
    "                             logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "\n",
    "        return fknew_cust        \n",
    "\n",
    "    \n",
    "\n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]  \n",
    "\n",
    "    \n",
    "\n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "\n",
    "    a_bot[k[i], :] -= xi                         # offset if xi is in this subset\n",
    "\n",
    "    a_top = np.apply_along_axis(lambda row: row + xi, 1, a_bot)\n",
    "\n",
    "    fk_cust = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "\n",
    "     \n",
    "\n",
    "    # Convert back to a dense array in case X was sparse\n",
    "\n",
    "    return np.asarray(fk_cust).ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mnom_fk_tabl(jj, tt, x, j, t, k, Kmax, L, ha, new=False):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "\n",
    "    \n",
    "\n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    x_jt = x[np.logical_and(j == jj, t == tt), :]                                # (|T|, L)\n",
    "\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "\n",
    "    n_jt = np.sum(x_jt, axis=1)                                                  # (|T|,)\n",
    "\n",
    "    sum_jt = np.sum(x_jt, axis=0)                                                # (L,)\n",
    "\n",
    "    log_con = np.sum(logg(n_jt + 1)) - np.sum(logg(x_jt + 1))    # term constant for all k\n",
    "\n",
    "    \n",
    "\n",
    "    fknew_tabl = np.exp( log_con + np.sum(logg(sum_jt + ha)) - logg(np.sum(sum_jt + ha)) + \n",
    "\n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "\n",
    "    if x_jt.shape[0] == 0:\n",
    "\n",
    "        #print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "\n",
    "        new = True\n",
    "\n",
    "    if new == True: return fknew_tabl       \n",
    "\n",
    "    \n",
    "\n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]\n",
    "\n",
    "      \n",
    "\n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "\n",
    "    a_bot[kk[0], :] -= sum_jt                       # offset if table x_jt is in this subset\n",
    "\n",
    "    a_top = a_bot + sum_jt[None, :]\n",
    "\n",
    "    fk_tabl = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "\n",
    "\n",
    "\n",
    "    return fk_tabl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cat_fk_cust(i, x, k, Kmax, L, ha, new=False):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "\n",
    "                        F(x|phi) ~ Categorical(L, phi_1,...,phi_L)\n",
    "\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "\n",
    "    X can be a dense or a sparse csr-style matrix.\n",
    "\n",
    "    \n",
    "\n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    xi = x[i, :]\n",
    "\n",
    "    ll = sparse.find(xi)[0][0]        # get index of the 1 value\n",
    "\n",
    "    # Calculate the case where k has no members\n",
    "\n",
    "    if new == True:\n",
    "\n",
    "        return ha[ll] / np.sum(ha)    \n",
    "\n",
    "    \n",
    "\n",
    "    # Store the size of sets V and V_l for each k\n",
    "\n",
    "    V_kks = np.array([np.sum(k == kk) for kk in range(Kmax)])\n",
    "\n",
    "    Vl_kks = np.array([np.sum(x[k == kk, ll]) for kk in range(Kmax)])\n",
    "\n",
    "    \n",
    "\n",
    "    fk_cust = (Vl_kks + ha[ll]) / (V_kks + np.sum(ha))\n",
    "\n",
    "    return fk_cust\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class StirlingEngine:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Numerically efficient engine for computing and storing computed Stirling numbers.\n",
    "\n",
    "    \n",
    "\n",
    "    CONSTRUCTOR PARAMETERS\n",
    "\n",
    "    - Nmax: largest integer n for which s(n,m) will need to be computed\n",
    "\n",
    "    \n",
    "\n",
    "    PRIVATE ATTRIBUTES\n",
    "\n",
    "    - s_memo_, slog_memo_: running tables of previously computed values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    def __init__(self, Nmax):\n",
    "\n",
    "        self.s_memo_ = np.full((Nmax, Nmax), np.nan)\n",
    "\n",
    "        self.slog_memo_ = np.full((Nmax, Nmax), np.nan)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def stirling(self, n, m):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Computes an unsigned Stirling number of the first kind.\n",
    "\n",
    "        Uses dynamic programming to store previously computed s(n,m) values,\n",
    "\n",
    "        as this is a repeatedly-called recursive algorithm.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        assert n < self.s_memo_.shape[0] and m < self.s_memo_.shape[0]  \n",
    "\n",
    "        # If this has already been computed, return stored value\n",
    "\n",
    "        if not np.isnan(self.s_memo_[n, m]):\n",
    "\n",
    "            return self.s_memo_[n, m]\n",
    "\n",
    "        else:\n",
    "\n",
    "            return_val = np.nan\n",
    "\n",
    "\n",
    "\n",
    "            # Base cases\n",
    "\n",
    "            if (n == 0 and m == 0) or (n == 1 and m == 1):\n",
    "\n",
    "                return_val = 1\n",
    "\n",
    "            elif (n > 0 and m == 0) or m > n:\n",
    "\n",
    "                return_val = 0\n",
    "\n",
    "            # Recursion relation\n",
    "\n",
    "            else:\n",
    "\n",
    "                return_val = self.stirling(n-1, m-1) + (n-1)*self.stirling(n-1, m)\n",
    "\n",
    "\n",
    "\n",
    "            self.s_memo_[n, m] = return_val\n",
    "\n",
    "            return return_val\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def stirlog(self, n, m):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Computes the natural logarithm of an unsigned Stirling number,\n",
    "\n",
    "        using the same dynamic programming approach as above.\n",
    "\n",
    "        If s(n,m) = 0, this gets returned as -inf (np.exp(-inf) == 0.0)\n",
    "\n",
    "        \n",
    "\n",
    "        This is the preferred function, as stirling() can encounter overflow errors.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        assert n < self.slog_memo_.shape[0] and m < self.slog_memo_.shape[0]  \n",
    "\n",
    "        # If this has already been computed, return stored value\n",
    "\n",
    "        if not np.isnan(self.slog_memo_[n, m]):\n",
    "\n",
    "            return self.slog_memo_[n, m]\n",
    "\n",
    "        else:\n",
    "\n",
    "            return_val = np.nan\n",
    "\n",
    "\n",
    "\n",
    "            # Base cases\n",
    "\n",
    "            if (n == 0 and m == 0) or (n == 1 and m == 1):\n",
    "\n",
    "                return_val = 0\n",
    "\n",
    "            elif (n > 0 and m == 0) or m > n:\n",
    "\n",
    "                return_val = -np.inf\n",
    "\n",
    "            # Recursion relation\n",
    "\n",
    "            else:\n",
    "\n",
    "                log_s1, log_s2 = self.stirlog(n-1, m-1), self.stirlog(n-1, m)\n",
    "\n",
    "                # If s1 == 0 (log_s1 == -inf), just return (n-1)*log_s2\n",
    "\n",
    "                # By definition, must have s2 > s1, so only need to check s1\n",
    "\n",
    "                if np.isfinite(log_s1):\n",
    "\n",
    "                    val = (n-1) * np.exp(log_s2 - log_s1)\n",
    "\n",
    "                    # If there is overflow/underflow in `val`, approximate log(1+x) = log(x)\n",
    "\n",
    "                    if np.isfinite(val):\n",
    "\n",
    "                        return_val = log_s1 + np.log1p(val)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        return_val = log_s2 + np.log(n-1)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    return_val = log_s2 + np.log(n-1)\n",
    "\n",
    "\n",
    "\n",
    "            self.slog_memo_[n, m] = return_val\n",
    "\n",
    "            return return_val\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "class HDP:\n",
    "    \"\"\"\n",
    "    Model implementing the Chinese Restaurant Franchise Process formulation of the HDP.\n",
    "\n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - gamma, alpha0: scaling parameters > 0 for base measures H and G0\n",
    "    - f: string representing distribution of data; h is chosen to be conjugate\n",
    "    - hypers: tuple of hyperparameter values specific to f/h scheme chosen\n",
    "\n",
    "    PRIVATE ATTRIBUTES (volatile)\n",
    "    - tk_map_: (J x Tmax) matrix of k values for each (j,t) pair\n",
    "    - beta_: (Kmax + 1,) vector of beta values for each k\n",
    "    - n_: (J x Tmax) matrix specifying counts of customers (gibbs_cfr)\n",
    "    - q_: (J x Kmax) matrix specifying counts of customers (gibbs_direct)\n",
    "    - m_: (J x Kmax) matrix specifying counts of tables\n",
    "    - fk_cust_, fk_tabl_: functions to compute mixing components for Gibbs sampling\n",
    "    - stir_: an object of class StirlingEngine which computes Stirling numbers\n",
    "\n",
    "    PUBLIC ATTRIBUTES\n",
    "    cfr_samples: (S x N x 2) matrix of (t, k) values for each data point i;\n",
    "                 exists only after gibbs_cfr() has been called\n",
    "    direct_samples: (S x N) matrix of k values for each data point i;\n",
    "                    exists only after gibbs_direct() has been called\n",
    "    beta_samples: (S x Kmax+1) matrix of beta values after each iteration;\n",
    "                  exists only after gibbs_direct() has been called\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=1, alpha0=1, f='multinomial', hypers=None):\n",
    "        self.g_ = gamma\n",
    "        self.a0_ = alpha0\n",
    "        self.set_priors(f, hypers)\n",
    "        \n",
    "\n",
    "    def set_priors(self, f, hypers):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Initializes the type of base measure h_ and data-generation function f_.\n",
    "\n",
    "        Also sets hypers_, the relevelant hyperparameters and\n",
    "\n",
    "                  fk_routine_, the function to compute mixing components.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if f == 'poisson':\n",
    "\n",
    "            # Specify parameters of H ~ Gamma(a,b)\n",
    "\n",
    "            if hypers is None:\n",
    "\n",
    "                self.hypers_ = (1,1)\n",
    "\n",
    "            else: self.hypers_ = hypers\n",
    "\n",
    "            self.fk_cust_ = pois_fk_cust\n",
    "\n",
    "            self.fk_tabl_ = pois_fk_tabl\n",
    "\n",
    "        \n",
    "\n",
    "        elif f == 'multinomial':\n",
    "\n",
    "            if hypers is None:\n",
    "\n",
    "                L = 2\n",
    "\n",
    "                self.hypers_ = (L, np.ones(L))\n",
    "\n",
    "            else: self.hypers_ = hypers\n",
    "\n",
    "            self.fk_cust_ = mnom_fk_cust\n",
    "\n",
    "            self.fk_tabl_ = mnom_fk_tabl\n",
    "\n",
    "            \n",
    "\n",
    "        elif f == 'categorical':\n",
    "\n",
    "            # Identical to multinomial, but with some efficiency upgrades\n",
    "\n",
    "            if hypers is None:\n",
    "\n",
    "                L = 2\n",
    "\n",
    "                self.hypers_ = (L, np.ones(L))\n",
    "\n",
    "            else: self.hypers_ = hypers\n",
    "\n",
    "            self.fk_cust_ = cat_fk_cust\n",
    "\n",
    "            self.fk_tabl_ = mnom_fk_tabl\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def tally_up(self, it, which=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function for computing maps and counts in gibbs().\n",
    "\n",
    "        Given a current iteration in the cfr_samples attribute, does a full\n",
    "\n",
    "        recount of customer/table allocations, updating n_ and m_.\n",
    "\n",
    "        Set which = 'n' or 'm' to only tally up that portion\n",
    "\n",
    "        \"\"\"    \n",
    "\n",
    "        \n",
    "\n",
    "        if which == 'n':\n",
    "\n",
    "            jt_pairs = self.cfr_samples[it,:,0:2]\n",
    "\n",
    "            # Count customers at each table (jt)\n",
    "\n",
    "            cust_counts = pd.Series(map(tuple, jt_pairs)).value_counts()\n",
    "\n",
    "            j_idx, t_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "\n",
    "            self.n_ *= 0\n",
    "\n",
    "            self.n_[j_idx, t_idx] = cust_counts\n",
    "\n",
    "            \n",
    "\n",
    "        elif which == 'm':\n",
    "\n",
    "            jt_pairs = self.cfr_samples[it,:,0:2]\n",
    "\n",
    "            # First filter by unique tables (jt), then count tables with each k value\n",
    "\n",
    "            jt_unique, k_idx = np.unique(jt_pairs, axis=0, return_index=True)\n",
    "\n",
    "            jk_pairs = np.c_[self.cfr_samples[it, k_idx, 0],\n",
    "\n",
    "                             self.cfr_samples[it, k_idx, 2]]\n",
    "\n",
    "            #print(jk_pairs)\n",
    "\n",
    "            tabl_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "\n",
    "            #print(tabl_counts)\n",
    "\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*tabl_counts.index)))\n",
    "\n",
    "            self.m_ *= 0\n",
    "\n",
    "            self.m_[j_idx, k_idx] = tabl_counts\n",
    "\n",
    "            \n",
    "\n",
    "        elif which == 'q':\n",
    "\n",
    "            jk_pairs = self.direct_samples[it,:,:]\n",
    "\n",
    "            # Counts customers at each j eating k\n",
    "\n",
    "            cust_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "\n",
    "            self.q_ *= 0\n",
    "\n",
    "            self.q_[j_idx, k_idx] = cust_counts\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "    def get_dist(self, old, new, used, size):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function which standardizes the operation of computing a\n",
    "\n",
    "        full conditional distribution, for both t and k values.\n",
    "\n",
    "        Also normalizes and ensures there are no NANs.\n",
    "\n",
    "        - old: a (size,) vector of probability values for used values\n",
    "\n",
    "        - new: a scalar representing the combined probability of all unused values\n",
    "\n",
    "        - used: a (size,) mask encoding which values in the sample space are being used\n",
    "\n",
    "        - size: the size of the sample space\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        num_unused = size - np.sum(used)\n",
    "\n",
    "        dist = None\n",
    "\n",
    "        if num_unused == 0:\n",
    "\n",
    "            # In our truncated sample space, there is no room for \"new\" values\n",
    "\n",
    "            dist = old\n",
    "\n",
    "        else:\n",
    "\n",
    "            dist = old * used + (new / num_unused) * np.logical_not(used)\n",
    "\n",
    "        \n",
    "\n",
    "        # Remove nans and add epsilon so that distribution is all positive\n",
    "\n",
    "        dist[np.isnan(dist)] = 0\n",
    "\n",
    "        dist += 1e-10\n",
    "\n",
    "        return dist / np.sum(dist)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def draw_t(self, it, x, j, Tmax, Kmax, verbose):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "\n",
    "        Called by gibbs_cfr()\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        t_next, k_next = self.cfr_samples[it,:,1], self.cfr_samples[it,:,2]\n",
    "\n",
    "        # Cycle through the t value of each customer, conditioning on everything\n",
    "\n",
    "        # Randomize the order in which updates occur\n",
    "\n",
    "        for i in np.random.permutation(len(j)):\n",
    "\n",
    "            jj, tt0, kk0 = j[i], t_next[i], k_next[i]\n",
    "\n",
    "\n",
    "\n",
    "            # Get vector of customer f_k values (dependent on model specification)\n",
    "\n",
    "            old_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_) \n",
    "\n",
    "            new_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_, new=True) \n",
    "\n",
    "            # Calculate pointwise likelihoods p(x_ji | ...)\n",
    "\n",
    "            M = np.sum(self.m_)\n",
    "\n",
    "            Mk = np.sum(self.m_, axis=0)   # number of tables serving k\n",
    "\n",
    "            lik = old_mixes @ (Mk / (M + self.g_)) + new_mixes * (self.g_ / (M + self.g_))\n",
    "\n",
    "\n",
    "\n",
    "            cust_offset = np.zeros(Tmax)\n",
    "\n",
    "            cust_offset[tt0] = 1\n",
    "\n",
    "            old_t = (self.n_[jj, :] - cust_offset) * old_mixes[self.tk_map_[jj, :]]      \n",
    "\n",
    "            new_t = self.a0_ * lik\n",
    "\n",
    "            # If a table is in use, prob comes from old_t; otherwise, from new_t\n",
    "\n",
    "            # Distribute the weight of new_t across all possible new allocations\n",
    "\n",
    "            t_used = self.n_[jj, :] > 0\n",
    "\n",
    "            t_dist = self.get_dist(old_t, new_t, t_used, Tmax)\n",
    "\n",
    "\n",
    "\n",
    "            tt1 = np.random.choice(Tmax, p=t_dist)\n",
    "\n",
    "            t_next[i] = tt1\n",
    "\n",
    "            self.tally_up(it, which='n')\n",
    "\n",
    "\n",
    "\n",
    "            # If this table was previously unoccupied, we need to select a k\n",
    "\n",
    "            if self.n_[jj, tt1] == 1 and tt0 != tt1:\n",
    "\n",
    "                old_k = np.sum(self.m_, axis=0) * old_mixes\n",
    "\n",
    "                new_k = self.g_ * new_mixes\n",
    "\n",
    "                k_used = np.sum(self.m_, axis=0) > 0\n",
    "\n",
    "                k_dist = self.get_dist(old_k, new_k, k_used, Kmax)\n",
    "\n",
    "\n",
    "\n",
    "                kk1 = np.random.choice(Kmax, p=k_dist)\n",
    "\n",
    "                self.tk_map_[jj, tt1] = kk1\n",
    "\n",
    "                k_next[i] = self.tk_map_[jj, tt1]\n",
    "\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "\n",
    "\n",
    "            #if verbose: print(f\"~ customer (j,i) = {(jj,i)}\" +\n",
    "\n",
    "                              #f\" moves table: {tt0} -> {t_next[i]}, k: {kk0} -> {k_next[i]}\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def draw_k(self, it, x, j, Kmax, verbose):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "\n",
    "        Called by gibbs_cfr()\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        t_next, k_next = self.cfr_samples[it,:,1], self.cfr_samples[it,:,2]\n",
    "\n",
    "        # Cycle through the k values of each table\n",
    "\n",
    "        j_idx, t_idx = np.where(self.n_ > 0)   # find the occupied tables\n",
    "\n",
    "        for i in np.random.permutation(len(j_idx)):\n",
    "\n",
    "            jj, tt = j_idx[i], t_idx[i]\n",
    "\n",
    "            kk0 = self.tk_map_[jj, tt]\n",
    "\n",
    "\n",
    "\n",
    "            # Get vector of table f_k values (dependent on model specification)\n",
    "\n",
    "            old_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_) \n",
    "\n",
    "            new_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_, new=True) \n",
    "\n",
    "\n",
    "\n",
    "            tabl_offset = np.zeros(Kmax)\n",
    "\n",
    "            tabl_offset[kk0] = 1\n",
    "\n",
    "            old_k = (np.sum(self.m_, axis=0) - tabl_offset) * old_mixes\n",
    "\n",
    "            new_k = self.g_ * new_mixes\n",
    "\n",
    "            k_used = np.sum(self.m_, axis=0) > 0\n",
    "\n",
    "            k_dist = self.get_dist(old_k, new_k, k_used, Kmax)\n",
    "\n",
    "\n",
    "\n",
    "            kk1 = np.random.choice(Kmax, p=k_dist)\n",
    "\n",
    "            self.tk_map_[jj, tt] = kk1\n",
    "\n",
    "            k_next[np.logical_and(j == jj, t_next == tt)] = kk1\n",
    "\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "\n",
    "\n",
    "            #if verbose: print(f\"~~ table (j,t) = {(jj,tt)} changes dish: {kk0} -> {kk1}\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def draw_z(self, it, x, j, Kmax, verbose):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function which does the draws from the z_ij full conditional.\n",
    "\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "\n",
    "        Called by gibbs_direct()\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        k_next = self.direct_samples[it,:,1]\n",
    "\n",
    "        # Cycle through the k values of each customer\n",
    "\n",
    "        for i in np.random.permutation(len(j)):\n",
    "\n",
    "            jj, kk0 = j[i], k_next[i]\n",
    "\n",
    "            \n",
    "\n",
    "            # Get vector of customer f_k values (dependent on model specification)\n",
    "\n",
    "            old_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_) \n",
    "\n",
    "            new_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_, new=True) \n",
    "\n",
    "            \n",
    "\n",
    "            cust_offset = np.zeros(Kmax)\n",
    "\n",
    "            cust_offset[kk0] = 1\n",
    "\n",
    "            old_k = (self.q_[jj, :] - cust_offset +\n",
    "\n",
    "                     self.a0_ * self.beta_samples[it, :-1]) * old_mixes      \n",
    "\n",
    "            new_k = self.a0_ * self.beta_samples[it, -1] * new_mixes\n",
    "\n",
    "            k_used = np.sum(self.m_, axis=0) > 0\n",
    "\n",
    "            k_dist = self.get_dist(old_k, new_k, k_used, Kmax)\n",
    "\n",
    "\n",
    "\n",
    "            kk1 = np.random.choice(Kmax, p=k_dist)\n",
    "\n",
    "            k_next[i] = kk1\n",
    "\n",
    "            self.tally_up(it, which='q')\n",
    "\n",
    "            \n",
    "\n",
    "            # If this k value was previously unused, must also set the beta_k component\n",
    "\n",
    "            if np.sum(self.q_[:, kk1] == 1):\n",
    "\n",
    "                b = np.random.beta(1, self.g_)\n",
    "\n",
    "                beta_u = self.beta_samples[it, -1]\n",
    "\n",
    "                self.beta_samples[it, kk1] = b * beta_u\n",
    "\n",
    "                self.beta_samples[it, -1] = (1-b) * beta_u\n",
    "\n",
    "            \n",
    "\n",
    "            #if verbose:\n",
    "\n",
    "                #print(f\"~ customer (j,i) = {(jj,i)}\" +\n",
    "\n",
    "                      #f\"changes dish: {kk0} -> {kk1}\")\n",
    "\n",
    "                #print(f\"  k_dist: {k_dist.round(3)} (sum {np.sum(k_dist)})\")\n",
    "\n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "    def draw_m(self, it, x, j, Kmax, verbose):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Helper function which does the draws from the z_ij full conditional.\n",
    "\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "\n",
    "        Called by gibbs_direct()\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        k_next = self.direct_samples[it,:,1]\n",
    "\n",
    "        self.m_ *= 0                           # reset the m counts\n",
    "\n",
    "        # Cycle through the k values of each restaurant\n",
    "        j_idx, k_idx = np.where(self.q_ > 0)   # find the consumed dishes\n",
    "        for i in np.random.permutation(len(j_idx)):\n",
    "            jj, kk = j_idx[i], k_idx[i]\n",
    "            max_m = self.q_[jj, kk]\n",
    "            \n",
    "            abk = self.a0_ * self.beta_samples[it, kk]\n",
    "            m_range = np.arange(max_m) + 1\n",
    "            log_s = np.array([self.stir_.stirlog(max_m, m) for m in m_range])\n",
    "            m_dist = np.exp( logg(abk) - logg(abk + max_m) +\n",
    "                             log_s + m_range * np.log(abk) )\n",
    "            \"\"\"MOSTLY FIXED.  m_dist should be a proper distribution\"\"\"\n",
    "            m_dist[np.isnan(m_dist)] = 0\n",
    "            m_dist += 1e-6\n",
    "            \n",
    "            mm1 = np.random.choice(m_range, p=m_dist/np.sum(m_dist))\n",
    "            self.m_[jj, kk] = mm1\n",
    "\n",
    "            #if verbose:\n",
    "                #print(f\"~~ restaraunt {jj}: {mm1} tables / {max_m} customers eating {kk}\")\n",
    "                #print(f\"m_dist: {m_dist.round(3)}\")\n",
    "                \n",
    "    \n",
    "    def gibbs_cfr(self, x, j, iters, Tmax=None, Kmax=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of t and k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Tmax: maximum number of clusters for each group\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        returns: this HDP object with cfr_samples attribute\n",
    "        \"\"\"\n",
    "        \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        J, N = np.max(j) + 1, len(j)\n",
    "        # Set default Tmax and Kmax, if not provided\n",
    "        if Tmax is None: Tmax = min(100, np.max(group_counts))\n",
    "        if Kmax is None: Kmax = min(100, N)\n",
    "            \n",
    "        self.n_ = np.zeros((J, Tmax), dtype='int')\n",
    "        self.m_ = np.zeros((J, Kmax), dtype='int')\n",
    "        self.cfr_samples = np.zeros((iters+1, N, 3), dtype='int')\n",
    "        self.cfr_samples[:,:,0] = j\n",
    "        \n",
    "        # Set random initial values for t and k assignments\n",
    "        t0, k0 = self.cfr_samples[0,:,1], self.cfr_samples[0,:,2]\n",
    "        t0[:] = np.random.randint(0, Tmax, size=N)\n",
    "        self.tk_map_ = np.random.randint(0, Kmax//2, (J, Tmax))\n",
    "        self.tally_up(it=0, which='n')\n",
    "        for jj in range(J):\n",
    "            for tt in np.where(self.n_[jj, :] > 0)[0]:\n",
    "                #print(f\"mapping: {(jj, tt)} -> {self.tk_map_[jj, tt]}\")\n",
    "                k0[np.logical_and(j == jj, t0 == tt)] = self.tk_map_[jj, tt]\n",
    "        self.tally_up(it=0, which='m')\n",
    "\n",
    "        \n",
    "        for s in range(iters):\n",
    "            t_prev, k_prev = self.cfr_samples[s,:,1], self.cfr_samples[s,:,2]\n",
    "            t_next, k_next = self.cfr_samples[s+1,:,1], self.cfr_samples[s+1,:,2]\n",
    "            # Copy over the previous iteration as a starting point\n",
    "            t_next[:], k_next[:] = t_prev, k_prev\n",
    "            \n",
    "            self.draw_t(s+1, x, j, Tmax, Kmax, verbose)\n",
    "            self.draw_k(s+1, x, j, Kmax, verbose)\n",
    "        \n",
    "        self.cfr_samples = self.cfr_samples[1:,:,1:]\n",
    "        return self  \n",
    "    \n",
    "    \n",
    "    def gibbs_direct(self, x, j, iters, Kmax=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        returns: this HDP object with direct_samples attribute\n",
    "        \"\"\"\n",
    "        \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        J, N = np.max(j) + 1, len(j)\n",
    "        if Kmax is None: Kmax = min(100, N)\n",
    "            \n",
    "        self.q_ = np.zeros((J, Kmax), dtype='int')   # performs the same function as n_\n",
    "        self.m_ = np.zeros((J, Kmax), dtype='int')\n",
    "        self.direct_samples = np.zeros((iters+1, N, 2), dtype='int')\n",
    "        self.direct_samples[:,:,0] = j\n",
    "        self.beta_samples = np.zeros((iters+1, Kmax+1))\n",
    "        \n",
    "        self.stir_ = StirlingEngine(np.max(group_counts) + 1)\n",
    "        np.seterr('ignore')\n",
    "        \n",
    "        # Set random initial values for k assignments\n",
    "        k0 = self.direct_samples[0,:,1]\n",
    "        k0[:] = np.random.randint(0, Kmax, size=N)\n",
    "        self.tally_up(it=0, which='q')\n",
    "        # Implicitly set random t assignments by drawing possible m counts (m_jk <= q_jk)\n",
    "        for jj in range(J):\n",
    "            for kk in range(Kmax):\n",
    "                max_m = self.q_[jj, kk]\n",
    "                if max_m == 1:\n",
    "                    self.m_[jj, kk] = 1\n",
    "                elif max_m > 1:\n",
    "                    self.m_[jj, kk] = np.random.randint(1, max_m)\n",
    "        # Compute the corresponding beta values from m assignments\n",
    "        Mk = np.sum(self.m_, axis=0)\n",
    "        self.beta_samples[0,:] = np.random.dirichlet(np.append(Mk, self.g_) + 1e-10)\n",
    "        \n",
    "        for s in range(iters):\n",
    "            # Copy over the previous iteration as a starting point\n",
    "            self.direct_samples[s+1,:,1] = self.direct_samples[s,:,1] \n",
    "            self.beta_samples[s+1,:] = self.beta_samples[s,:]\n",
    "            \n",
    "            self.draw_z(s+1, x, j, Kmax, verbose)\n",
    "            self.draw_m(s+1, x, j, Kmax, verbose)\n",
    "            \n",
    "            Mk = np.sum(self.m_, axis=0)\n",
    "            # Dirichlet weights must be > 0, so in case some k is unused, add epsilon\n",
    "            self.beta_samples[s+1,:] = np.random.dirichlet(np.append(Mk, self.g_) + 1e-10)\n",
    "            if verbose: print(self.beta_samples[s+1,:].round(3))\n",
    "        \n",
    "        self.direct_samples = self.direct_samples[1:,:,1]\n",
    "        self.beta_samples = self.beta_samples[1:,:]\n",
    "        return self\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('reuters_x.csv')\n",
    "x = np.array(x.iloc[:,1])\n",
    "\n",
    "j = pd.read_csv('reuters_j.csv')\n",
    "j = np.array(j.iloc[:,1])\n",
    "\n",
    "# Get a prior distribution over the vocabulary from selected documents\n",
    "#L, h_alpha = x.shape[1], np.sum(x, axis=0)\n",
    "h_alpha = np.sum(x, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ca13154f971b>\u001b[0m in \u001b[0;36mgibbs_direct\u001b[1;34m(self, x, j, iters, Kmax, verbose)\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ca13154f971b>\u001b[0m in \u001b[0;36mdraw_z\u001b[1;34m(self, it, x, j, Kmax, verbose)\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[1;31m# Get vector of customer f_k values (dependent on model specification)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m             \u001b[0mold_mixes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfk_cust_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0mnew_mixes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfk_cust_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ca13154f971b>\u001b[0m in \u001b[0;36mcat_fk_cust\u001b[1;34m(i, x, k, Kmax, L, ha, new)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m     \u001b[0mxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m# get index of the 1 value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "%time hdp = HDP(f='categorical', hypers=(1, np.sum(x, axis = 0))).gibbs_direct(x, j, 10, Kmax=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
