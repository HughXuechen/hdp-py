{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP Gibbs Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.1 )* Posterior Sampling in the Chinese Restaurant Franchise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview\n",
    "\n",
    "The Hierarchical Dirichlet Process mixture model is given by\n",
    "$$\\begin{aligned}\n",
    "G_0 | \\gamma, H &\\sim DP(\\gamma, H) \\\\\n",
    "G_j | \\alpha_0, G_0 &\\sim DP(\\alpha_0, G_0) \\\\\n",
    "\\theta_{ji} | G_j &\\sim G_j \\\\\n",
    "x_{ji} | \\theta_{ji} &\\sim F(\\theta_{ji})\n",
    "\\end{aligned} $$\n",
    "\n",
    "This model is able to non-parametrically cluster each group's data while sharing information both between and within groups.  A Dirichlet process is essentially a discrete distribution with atoms drawn from a (not-necessarily discrete) base measure $H$ and gradually decreasing weights determined by the \"stick-breaking process.\"  In the HDP, each group is a Dirichlet process drawn from another DP $G_0$, so these will contain the same atoms as $G_0$ but with different weights:\n",
    "$$\\begin{aligned}\n",
    "G_0 &= \\sum_{k=1}^{\\infty} \\beta_k \\delta(\\phi_k) \\\\\n",
    "G_j &= \\sum_{k=1}^{\\infty} \\pi_{jk} \\delta(\\phi_k) \\\\\n",
    "\\phi_k | H &\\sim H\n",
    "\\end{aligned} $$\n",
    "Additionally, if we define $\\beta, \\pi_j$ as the collected weights above, it can be shown that these vectors encode a distribution over $\\mathbb{Z}^+$ such that $\\beta | \\gamma \\sim GEM(\\gamma)$ and $\\pi_j | \\alpha_0, \\beta \\sim DP(\\alpha_0, \\beta)$.\n",
    "\n",
    "Successive draws from a DP exhibit clustering behavior, since the probability of taking a certain value is a related to the number of previous draws of that value.  This is shown in the hierarchical sense by the *Chinese restaurant franchise* process.  Imagine a group of Chinese restaurants with a certain number of tables at each restaurant.  Let $\\phi_k$ be the global dishes, drawn from $H$; $\\psi_{jt}$ be the table-specific dishes, drawn from $G_0$; and $\\theta_{ji}$ be the customer-specific dishes, drawn from $G_j$.  Denote $z_{ji}$ as the dish index eaten by customer $ji$; $t_{ji}$ as the table index where customer $ji$ sits; $k_{jt}$ be the dish index served at table $jt$; $n_{jtk}$ be the customer counts; and $m_{jk}$ be the table counts.  Then:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\theta_{ji} | \\text{other } \\theta, \\alpha_0, G_0 &\\sim\n",
    "    \\sum_{t=1}^{m_{j\\cdot}} \\frac{n_{jt\\cdot}}{i-1+\\alpha_0} \\delta(\\psi_{jt}) +\n",
    "                            \\frac{\\alpha_0}{i-1+\\alpha_0} G_0 \\\\\n",
    "\\psi_{jt} | \\text{other } \\psi, \\gamma, H &\\sim\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} \\delta(\\phi_k) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} H\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Conditionals\n",
    "\n",
    "Choose some base measure $h(\\cdot)$ and a conjugate data-generating distribution $f(\\cdot | \\theta)$.  Important to compute are $f_k^{-x_{ji}}(x_{ji})$, the mixture component of customer $ij$ under $k$, and $f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, the mixture component of table $jt$ under $k$.  This is done by integrating out $\\phi_k$ over the joint density of all such points, for example:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac { \\int f(x_{ij} | \\phi_k) g(k)d\\phi_k } { \\int g(k)d\\phi_k } \\\\\n",
    "g(k) &= h(\\phi_k) \\prod_{j'i' \\neq ji, z_{j'i'} = k} f(x_{j'i'} | \\phi_k) \n",
    "\\end{aligned} $$\n",
    "\n",
    "The corresponding mixture components for a new customer assignment and new table assignment are denoted $f_{k^*}^{-x_{ji}}(x_{ji})$ and $f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, which are special cases of their the respective $f_k$ component where no data points have $z_{ij} = k^*$.\n",
    "\n",
    "Using this, we first compute the likelihood of a given point $x_{ji}$ given the current clustering scheme:\n",
    "$$\n",
    "p(x_{ji} | t^{-ji}, t_{ji} = t^*, k) =\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} f_k^{-x_{ji}}(x_{ji}) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} f_{k^*}^{-x_{ji}}(x_{ji})\n",
    "$$\n",
    "\n",
    "For efficiency, the Gibbs scheme implemented below only samples the $t$ and $k$ indexes (which can later be reverse-engineered to obtain the actual parameters).  The state space of the $k$ values is technically infinite, and the number of tables/dishes currently associated with the data is undefined.  We keep a running list of active $t$ and $k$ values.  Each update step, each customer is assigned either to one of the existing tables or to a new table, and if a customer is assigned to a new table, a new $k$ corresponding value gets drawn; similarly, each table is assigned a dish, either from the existing dishes or with a new dish.  If a table/dish becomes unrepresented in the current scheme, it gets removed from its respective list.  The update full conditionals are:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "p(t_{ji} = t | t^{-ji}, k, ...) &\\propto \\begin{cases}\n",
    "    n_{jt\\cdot}^{-ji} f_{k_{jt}}^{-x_{ji}}(x_{ji}) & t\\text{ used}\\\\\n",
    "    \\alpha_0 p(x_{ji} | ...) & t\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "p(k_{jt} = k | t, k^{-jt}) &\\propto \\begin{cases}\n",
    "    m_{\\cdot k} f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ used}\\\\\n",
    "    \\gamma f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution-Specific Mixture Components\n",
    "\n",
    "The only part of this sampling algorithm that depends on the choice of the measures $H$ and $F$ are the mixture components $f_k$, so this is the only part that needs rewritten for each type of model.  Let\n",
    "$$ \\begin{aligned}\n",
    "V_{kji} &= \\{ j'i' : j'i' \\neq ji, z_{j'i'} = k \\} \\\\\n",
    "W_{kjt} &= \\{ j'i' : j't_{j'i'} \\neq jt, k_{j't_{j'i'} = k} \\} \\\\\n",
    "T_{jt} &= \\{ j'i': t_{j'i'} = jt \\} \\\\\n",
    "\\end{aligned} $$\n",
    "$V$ is the set of all customers (excluding customer $ij$) eating dish $k$; $W$ is the set of all customers at tables (excluding table $jt$) eating $k$; these correspond to the product terms in the mixture components.  By conjugacy rules and kernel tricks, each $f_k$ can be expressed as functions of these sets.  Each $f_{k^*}$ can be found by using the corresponding $f_k$ formula where $V$ or $W$ is the empty set.\n",
    "\n",
    "*F = Poisson, H = Gamma*\n",
    "$$ \\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac{1}{x_{ji}!} \\cdot\n",
    "    \\frac{\\Gamma(x_{ji} + \\alpha_v)}{(1 + \\beta_v)^{x_{ji} + \\alpha_v}} \\cdot\n",
    "    \\frac{(\\beta_v)^{\\alpha_v}}{\\Gamma(\\alpha_v)} \\\\\n",
    "f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) &= \\frac{1}{\\prod_T x_t!} \\cdot\n",
    "    \\frac{\\Gamma(\\sum_T x_t + \\alpha_w)}{(1 + \\beta_w)^{\\sum_T x_t + \\alpha_w}} \\cdot\n",
    "    \\frac{(\\beta_w)^{\\alpha_w}}{\\Gamma(\\alpha_w)} \\\\\n",
    "\\alpha_v &= \\sum_V x_v + \\alpha \\quad , \\quad \\beta_v = |V| + \\beta \\\\\n",
    "\\alpha_w &= \\sum_W x_w + \\alpha \\quad , \\quad \\beta_w = |W| + \\beta \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "*F = Normal (known variance), H = Normal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import loggamma as logg\n",
    "\n",
    "def pois_fk(x, t, k, tk, Kmax, ha, hb):\n",
    "    \"\"\"\n",
    "    Computes in one sweep the mixture components for each customer/table for each k.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: fk_cust = (N, Kmax) matrix\n",
    "             fk_tabl = (T, Kmax) matrix\n",
    "             fknew_cust = (N,) vector\n",
    "             fknew_tabl = (T,) vector\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    \n",
    "    fk_cust = np.zeros((len(k), Kmax))\n",
    "    fknew_cust = np.zeros(len(k))\n",
    "    \n",
    "    # FOR k WITH NO MEMBERS\n",
    "    fknew_cust = np.exp( -logg(x + 1) + logg(x + ha) - logg(ha) -\n",
    "                         (x + ha) * np.log(1 + hb) + ha * np.log(hb) )\n",
    "    \n",
    "    # FOR k WITH MEMBERS\n",
    "    for kk in range(Kmax):\n",
    "        x_kk = x[k == kk]               # subset of x values with value kk\n",
    "        x_in = (k == kk).astype('int')  # offset for x values in subset\n",
    "        # If a value for k is not used, same as the prior\n",
    "        if len(x_kk) == 0:\n",
    "            fk_cust[:, kk] = fknew_cust\n",
    "            continue\n",
    "        \n",
    "        # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "        a_denom = (np.sum(x_kk) - x_in*x) + ha\n",
    "        b_denom = (len(x_kk) - x_in) + hb\n",
    "        a_numer = x + a_denom\n",
    "        b_numer = 1 + b_denom\n",
    "        #print(f\"kk = {kk}, subset size = {len(x_kk)}\")\n",
    "        #print(f\"{np.c_[x,k,a_numer,a_denom,b_numer,b_denom]}\")\n",
    "        fk_cust[:, kk] = np.exp( -logg(x + 1) + logg(a_numer) - logg(a_denom) -\n",
    "                                 a_numer * np.log(b_numer) + a_denom * np.log(b_denom) )\n",
    "    \n",
    "    return [fk_cust, fknew_cust]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRP:\n",
    "    \"\"\"\n",
    "    Model implementing the Chinese Franchise Restaurant Process.\n",
    "    \n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - gamma, alpha0: scaling parameters > 0 for base measures H and G0\n",
    "    - f: string representing distribution of data; h is chosen to be conjugate\n",
    "    - hypers: tuple of hyperparameter values specific to f/h scheme chosen\n",
    "    \n",
    "    PRIVATE ATTRIBUTES (volatile)\n",
    "    - t_: set of active t values; formatted as {j: set(t...), ...}\n",
    "    - k_: set of active k values\n",
    "    - tk_map_: (J x Tmax) matrix of k values for each (j,t) pair\n",
    "    - n_: (J x Tmax) matrix specifying counts of customers\n",
    "    - m_: (J x Kmax) matrix specifying counts of tables\n",
    "    - f_, h_: distribution functions\n",
    "    - fk_routine_: a function to compute mixing components for Gibbs sampling\n",
    "    \n",
    "    PUBLIC ATTRIBUTES\n",
    "    post_samples: (S x 4) matrix of (j, t, k, phi) values for each data point i;\n",
    "                  exists only after gibbs() has been called\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=1, alpha0=1, f='poisson', hypers=None):\n",
    "        self.g_ = gamma\n",
    "        self.a0_ = alpha0\n",
    "        self.set_priors(f, hypers)\n",
    "        \n",
    "    def set_priors(self, f, hypers):\n",
    "        \"\"\"\n",
    "        Initializes the type of base measure h_ and data-generation function f_.\n",
    "        Also sets hypers_, the relevelant hyperparameters and\n",
    "                  fk_routine_, the function to compute mixing components.\n",
    "        \"\"\"\n",
    "        if f == 'poisson':\n",
    "            # Specify parameters of H ~ Gamma(a,b)\n",
    "            if hypers is None:\n",
    "                self.hypers_ = (1,1)\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_routine_ = pois_fk\n",
    "    \n",
    "    \n",
    "    def tally_up(self, it, which=None):\n",
    "        \"\"\"\n",
    "        Helper function for computing maps and counts in gibbs().\n",
    "        Given a current iteration in the post_samples attribute, does a full\n",
    "        recount of customer/table allocations, updating n_ and m_.\n",
    "        Set which = 'n' or 'm' to only tally up that portion\n",
    "        \"\"\"\n",
    "        \n",
    "        jt_pairs = self.post_samples[it,:,0:2]\n",
    "        \n",
    "        if which != 'm':\n",
    "            # Count customers at each table (jt)\n",
    "            cust_counts = pd.Series(map(tuple, jt_pairs)).value_counts()\n",
    "            j_idx, t_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "            self.n_[j_idx, t_idx] += cust_counts\n",
    "            \n",
    "        if which != 'n':\n",
    "            # First filter by unique tables (jt), then count tables with each k value\n",
    "            jt_unique, k_idx = np.unique(jt_pairs, axis=0, return_index=True)\n",
    "            jk_pairs = np.c_[self.post_samples[it, k_idx, 0],\n",
    "                             self.post_samples[it, k_idx, 2]]\n",
    "            #print(jk_pairs)\n",
    "            tabl_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "            #print(tabl_counts)\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*tabl_counts.index)))\n",
    "            self.m_[j_idx, k_idx] += tabl_counts\n",
    "        \n",
    "        \n",
    "    def gibbs(self, x, j, iters=1, Kmax=10):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of t and k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        results: creation of post_samples attribute\n",
    "        \"\"\"\n",
    "            \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        # number of tables cannot exceed size of max group\n",
    "        J, Tmax, N = np.max(j) + 1, np.max(group_counts) + 1, len(j)\n",
    "        self.n_ = np.zeros((J, Tmax))\n",
    "        self.m_ = np.zeros((J, Kmax))\n",
    "        self.post_samples = np.zeros((iters+1, N, 4), dtype='int')\n",
    "        self.post_samples[:,:,0] = j\n",
    "        \n",
    "        # Set random initial values for t and k assignments\n",
    "        t0, k0 = self.post_samples[0,:,1], self.post_samples[0,:,2]\n",
    "        t0[:] = np.random.randint(1, Tmax, size=N)\n",
    "        self.tk_map_ = np.random.randint(1, Kmax//2, (J, Tmax))\n",
    "        self.tally_up(it=0, which='n')\n",
    "        for jj in range(J):\n",
    "            for tt in np.where(self.n_[jj, :] > 0)[0]:\n",
    "                #print(f\"mapping: {(jj, tt)} -> {self.tk_map_[jj, tt]}\")\n",
    "                k0[np.logical_and(j == jj, t0 == tt)] = self.tk_map_[jj, tt]\n",
    "        self.tally_up(it=0, which='m')\n",
    "        \n",
    "        for s in range(iters):\n",
    "            t_prev, k_prev = self.post_samples[s,:,1], self.post_samples[s,:,2]\n",
    "            t_next, k_next = self.post_samples[s+1,:,1], self.post_samples[s+1,:,2]\n",
    "            \n",
    "            # Get matrices of f_k values (dependent on model specification)\n",
    "            mixes = self.fk_routine_(x, t_prev, k_prev, self.tk_map_, Kmax, *self.hypers_) \n",
    "            self.fk_ = mixes\n",
    "            # Calculate pointwise likelihood \n",
    "            Mk = np.sum(self.m_, axis=0)   # number of tables serving k\n",
    "            lik = ( mixes[0] @ (Mk / (Mk + self.g_)) + \n",
    "                    np.tile(mixes[1][:,None], Kmax) @ (self.g_ / (Mk + self.g_)) )\n",
    "            self.lik_ = lik\n",
    "            \n",
    "            t_next = t_prev\n",
    "            # Cycle through each t value of each customer, conditioning on everything\n",
    "            # Randomize the order in which updates occur\n",
    "            for i in np.random.permutation(N):\n",
    "                continue\n",
    "                \n",
    "            k_next = k_prev\n",
    "            # Similarly, cycle through the k values of each table\n",
    "            for i in np.random.permutation(N):\n",
    "                continue            \n",
    "        \n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data\n",
    "N = 25\n",
    "np.random.seed(0)\n",
    "j = np.random.randint(1, 10, N)\n",
    "x = np.random.poisson(j, N)\n",
    "data = np.c_[x, j]\n",
    "\n",
    "c = CFRP(hypers=(1,10)).gibbs(x[:,None], j)\n",
    "iter0 = c.post_samples[0,:,:]\n",
    "#print(c.fk_)\n",
    "#print(np.c_[c.post_samples[0,:,2], np.argmax(c.fk_, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 2. 0. 0. 0. 0. 0.]]\n",
      "[[6 3 1 0]\n",
      " [1 5 1 0]\n",
      " [4 5 1 0]\n",
      " [4 3 1 0]\n",
      " [8 4 1 0]\n",
      " [4 4 4 0]\n",
      " [6 2 1 0]\n",
      " [3 3 4 0]\n",
      " [5 5 3 0]\n",
      " [8 4 1 0]\n",
      " [7 4 4 0]\n",
      " [9 2 4 0]\n",
      " [9 2 4 0]\n",
      " [2 2 2 0]\n",
      " [7 2 3 0]\n",
      " [8 3 1 0]\n",
      " [8 1 2 0]\n",
      " [9 4 4 0]\n",
      " [2 2 2 0]\n",
      " [6 5 1 0]\n",
      " [9 4 4 0]\n",
      " [5 2 1 0]\n",
      " [4 2 1 0]\n",
      " [1 3 4 0]\n",
      " [4 1 2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.26990434e-04, 1.31224069e+00, 5.23941875e-01, 7.44624745e-01,\n",
       "       4.26990434e-04, 5.23733255e-01, 1.56038830e-03, 1.31140398e+00,\n",
       "       9.83782403e-02, 1.52812166e-02, 4.16253425e-02, 2.22162572e-03,\n",
       "       1.71709570e-05, 5.12980035e-01, 1.89963906e-02, 9.35155726e-02,\n",
       "       9.79996891e-02, 4.16253425e-02, 1.31846192e+00, 3.36867777e-01,\n",
       "       1.86824208e-01, 4.02646250e-02, 4.02646250e-02, 6.68880021e+00,\n",
       "       1.89591123e-02])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t, k, log(customer mixtures)\n",
    "#print(np.log(c.fk_[0]).round(2))\n",
    "#print(c.n_)\n",
    "print(c.m_)\n",
    "print(iter0)\n",
    "mix = c.fk_[0]\n",
    "lik = c.lik_\n",
    "\n",
    "lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.2 )* Posterior Sampling with Augmented Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.3 )* Posterior Sampling by Direct Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
