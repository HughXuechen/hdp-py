{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP Gibbs Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.1 )* Posterior Sampling in the Chinese Restaurant Franchise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview\n",
    "\n",
    "The Hierarchical Dirichlet Process mixture model is given by\n",
    "$$\\begin{aligned}\n",
    "G_0 | \\gamma, H &\\sim DP(\\gamma, H) \\\\\n",
    "G_j | \\alpha_0, G_0 &\\sim DP(\\alpha_0, G_0) \\\\\n",
    "\\theta_{ji} | G_j &\\sim G_j \\\\\n",
    "x_{ji} | \\theta_{ji} &\\sim F(\\theta_{ji})\n",
    "\\end{aligned} $$\n",
    "\n",
    "This model is able to non-parametrically cluster each group's data while sharing information both between and within groups.  A Dirichlet process is essentially a discrete distribution with atoms drawn from a (not-necessarily discrete) base measure $H$ and gradually decreasing weights determined by the \"stick-breaking process.\"  In the HDP, each group is a Dirichlet process drawn from another DP $G_0$, so these will contain the same atoms as $G_0$ but with different weights:\n",
    "$$\\begin{aligned}\n",
    "G_0 &= \\sum_{k=1}^{\\infty} \\beta_k \\delta(\\phi_k) \\\\\n",
    "G_j &= \\sum_{k=1}^{\\infty} \\pi_{jk} \\delta(\\phi_k) \\\\\n",
    "\\phi_k | H &\\sim H\n",
    "\\end{aligned} $$\n",
    "Additionally, if we define $\\beta, \\pi_j$ as the collected weights above, it can be shown that these vectors encode a distribution over $\\mathbb{Z}^+$ such that $\\beta | \\gamma \\sim GEM(\\gamma)$ and $\\pi_j | \\alpha_0, \\beta \\sim DP(\\alpha_0, \\beta)$.\n",
    "\n",
    "Successive draws from a DP exhibit clustering behavior, since the probability of taking a certain value is a related to the number of previous draws of that value.  This is shown in the hierarchical sense by the *Chinese restaurant franchise* process.  Imagine a group of Chinese restaurants with a certain number of tables at each restaurant.  Let $\\phi_k$ be the global dishes, drawn from $H$; $\\psi_{jt}$ be the table-specific dishes, drawn from $G_0$; and $\\theta_{ji}$ be the customer-specific dishes, drawn from $G_j$.  Denote $z_{ji}$ as the dish index eaten by customer $ji$; $t_{ji}$ as the table index where customer $ji$ sits; $k_{jt}$ be the dish index served at table $jt$; $n_{jtk}$ be the customer counts; and $m_{jk}$ be the table counts.  Then:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\theta_{ji} | \\text{other } \\theta, \\alpha_0, G_0 &\\sim\n",
    "    \\sum_{t=1}^{m_{j\\cdot}} \\frac{n_{jt\\cdot}}{i-1+\\alpha_0} \\delta(\\psi_{jt}) +\n",
    "                            \\frac{\\alpha_0}{i-1+\\alpha_0} G_0 \\\\\n",
    "\\psi_{jt} | \\text{other } \\psi, \\gamma, H &\\sim\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} \\delta(\\phi_k) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} H\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Conditionals\n",
    "\n",
    "Choose some base measure $h(\\cdot)$ and a conjugate data-generating distribution $f(\\cdot | \\theta)$.  Important to compute is $f_k^{-x_{ji}}(x_{ji})$, the conditional density of a point $x_{ji}$ with mixture component $k$, after integrating out $\\phi_k$ over the joint density of all such points:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac { \\int f(x_{ij} | \\phi_k) g(k)d\\phi_k } { \\int g(k)d\\phi_k } \\\\\n",
    "g(k) &= \\prod_{j'i' \\neq ji, z_{j'i'} = k} f(x_j'i' | \\phi_k) h(\\phi_k)\n",
    "\\end{aligned} $$\n",
    "\n",
    "Using this, we first compute the likelihood of a given point $x_{ji}$ given the current clusering scheme:\n",
    "$$\n",
    "p(x_{ji} | t^{-ji}, t_{ji} = t^*, k) =\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} f_k^{-x_{ji}}(x_{ji}) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} f_{k^*}^{-x_{ji}}(x_{ji})\n",
    "$$\n",
    "where $f_k$ is the conditional density defined above and $f_{k^*} = \\int f(x_{ji} | \\phi) h(\\phi) d\\phi$ is the prior density of $x_{ji}$, found by integrating out all possible atoms $\\phi_k$.\n",
    "\n",
    "For efficiency, the Gibbs scheme implemented below only samples the $t$ and $k$ indexes (which can later be reverse-engineered to obtain the actual parameters).  The state space of the $k$ values is technically infinite, and the number of tables/dishes currently associated with the data is undefined.  We keep a running list of active $t$ and $k$ values.  Each update step, each customer is assigned either to one of the existing tables or to a new table, and if a customer is assigned to a new table, a new $k$ corresponding value gets drawn; similarly, each table is assigned a dish, either from the existing dishes or with a new dish.  If a table/dish becomes unrepresented in the current scheme, it gets removed from its respective list.  The update full conditionals are:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "p(t_{ji} = t | t^{-ji}, k, ...) &\\propto \\begin{cases}\n",
    "    n_{jt\\cdot}^{-ji} f_{k_{jt}}^{-x_{ji}}(x_{ji}) & t\\text{ used}\\\\\n",
    "    \\alpha_0 p(x_{ji} | ...) & t\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "p(k_{jt} = k | t, k^{-jt}) &\\propto \\begin{cases}\n",
    "    m_{\\cdot k} f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ used}\\\\\n",
    "    \\gamma f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.2 )* Posterior Sampling with Augmented Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.3 )* Posterior Sampling by Direct Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
