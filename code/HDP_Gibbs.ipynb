{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP Gibbs Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.1 )* Posterior Sampling in the Chinese Restaurant Franchise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview\n",
    "\n",
    "The Hierarchical Dirichlet Process mixture model is given by\n",
    "$$\\begin{aligned}\n",
    "G_0 | \\gamma, H &\\sim DP(\\gamma, H) \\\\\n",
    "G_j | \\alpha_0, G_0 &\\sim DP(\\alpha_0, G_0) \\\\\n",
    "\\theta_{ji} | G_j &\\sim G_j \\\\\n",
    "x_{ji} | \\theta_{ji} &\\sim F(\\theta_{ji})\n",
    "\\end{aligned} $$\n",
    "\n",
    "This model is able to non-parametrically cluster each group's data while sharing information both between and within groups.  A Dirichlet process is essentially a discrete distribution with atoms drawn from a (not-necessarily discrete) base measure $H$ and gradually decreasing weights determined by the \"stick-breaking process.\"  In the HDP, each group is a Dirichlet process drawn from another DP $G_0$, so these will contain the same atoms as $G_0$ but with different weights:\n",
    "$$\\begin{aligned}\n",
    "G_0 &= \\sum_{k=1}^{\\infty} \\beta_k \\delta(\\phi_k) \\\\\n",
    "G_j &= \\sum_{k=1}^{\\infty} \\pi_{jk} \\delta(\\phi_k) \\\\\n",
    "\\phi_k | H &\\sim H\n",
    "\\end{aligned} $$\n",
    "Additionally, if we define $\\beta, \\pi_j$ as the collected weights above, it can be shown that these vectors encode a distribution over $\\mathbb{Z}^+$ such that $\\beta | \\gamma \\sim GEM(\\gamma)$ and $\\pi_j | \\alpha_0, \\beta \\sim DP(\\alpha_0, \\beta)$.\n",
    "\n",
    "Successive draws from a DP exhibit clustering behavior, since the probability of taking a certain value is a related to the number of previous draws of that value.  This is shown in the hierarchical sense by the *Chinese restaurant franchise* process.  Imagine a group of Chinese restaurants with a certain number of tables at each restaurant.  Let $\\phi_k$ be the global dishes, drawn from $H$; $\\psi_{jt}$ be the table-specific dishes, drawn from $G_0$; and $\\theta_{ji}$ be the customer-specific dishes, drawn from $G_j$.  Denote $z_{ji}$ as the dish index eaten by customer $ji$; $t_{ji}$ as the table index where customer $ji$ sits; $k_{jt}$ be the dish index served at table $jt$; $n_{jtk}$ be the customer counts; and $m_{jk}$ be the table counts.  Then:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\theta_{ji} | \\text{other } \\theta, \\alpha_0, G_0 &\\sim\n",
    "    \\sum_{t=1}^{m_{j\\cdot}} \\frac{n_{jt\\cdot}}{i-1+\\alpha_0} \\delta(\\psi_{jt}) +\n",
    "                            \\frac{\\alpha_0}{i-1+\\alpha_0} G_0 \\\\\n",
    "\\psi_{jt} | \\text{other } \\psi, \\gamma, H &\\sim\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot \\cdot} + \\gamma} \\delta(\\phi_k) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot \\cdot} + \\gamma} H\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Conditionals\n",
    "\n",
    "Choose some base measure $h(\\cdot)$ and a conjugate data-generating distribution $f(\\cdot | \\theta)$.  Important to compute are $f_k^{-x_{ji}}(x_{ji})$, the mixture component of customer $ij$ under $k$, and $f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, the mixture component of table $jt$ under $k$.  This is done by integrating out $\\phi_k$ over the joint density of all such points, for example:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac { \\int f(x_{ij} | \\phi_k) g(k)d\\phi_k } { \\int g(k)d\\phi_k } \\\\\n",
    "g(k) &= h(\\phi_k) \\prod_{j'i' \\neq ji, z_{j'i'} = k} f(x_{j'i'} | \\phi_k) \n",
    "\\end{aligned} $$\n",
    "\n",
    "The corresponding mixture components for a new customer assignment and new table assignment are denoted $f_{k^*}^{-x_{ji}}(x_{ji})$ and $f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, which are special cases of their the respective $f_k$ component where no data points have $z_{ij} = k^*$.\n",
    "\n",
    "Using this, we first compute the likelihood of a given point $x_{ji}$ given the current clustering scheme:\n",
    "$$\n",
    "p(x_{ji} | t^{-ji}, t_{ji} = t^*, k) =\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot \\cdot} + \\gamma} f_k^{-x_{ji}}(x_{ji}) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot \\cdot} + \\gamma} f_{k^*}^{-x_{ji}}(x_{ji})\n",
    "$$\n",
    "\n",
    "For efficiency, the Gibbs scheme implemented below only samples the $t$ and $k$ indexes (which can later be reverse-engineered to obtain the actual parameters).  The state space of the $k$ values is technically infinite, and the number of tables/dishes currently associated with the data is undefined.  We keep a running list of active $t$ and $k$ values.  Each update step, each customer is assigned either to one of the existing tables or to a new table, and if a customer is assigned to a new table, a new $k$ corresponding value gets drawn; similarly, each table is assigned a dish, either from the existing dishes or with a new dish.  If a table/dish becomes unrepresented in the current scheme, it gets removed from its respective list.  The update full conditionals are:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "p(t_{ji} = t | t^{-ji}, k, ...) &\\propto \\begin{cases}\n",
    "    n_{jt\\cdot}^{-ji} f_{k_{jt}}^{-x_{ji}}(x_{ji}) & t\\text{ used}\\\\\n",
    "    \\alpha_0 p(x_{ji} | ...) & t\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "p(k_{jt} = k | t, k^{-jt}) &\\propto \\begin{cases}\n",
    "    m_{\\cdot k} f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ used}\\\\\n",
    "    \\gamma f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution-Specific Mixture Components\n",
    "\n",
    "The only part of this sampling algorithm that depends on the choice of the measures $H$ and $F$ are the mixture components $f_k$, so this is the only part that needs rewritten for each type of model.  Let\n",
    "$$ \\begin{aligned}\n",
    "V_{kji} &= \\{ j'i' : j'i' \\neq ji, z_{j'i'} = k \\} \\\\\n",
    "W_{kjt} &= \\{ j'i' : j't_{j'i'} \\neq jt, k_{j't_{j'i'}} = k \\} \\\\\n",
    "T_{jt} &= \\{ j'i': t_{j'i'} = jt \\} \\\\\n",
    "\\end{aligned} $$\n",
    "$V$ is the set of all customers (excluding customer $ij$) eating dish $k$; $W$ is the set of all customers at tables (excluding table $jt$) eating $k$; these correspond to the product terms in the mixture components.  By conjugacy rules and kernel tricks, each $f_k$ can be expressed as functions of these sets.  Each $f_{k^*}$ can be found by using the corresponding $f_k$ formula where $V$ or $W$ is the empty set.\n",
    "\n",
    "***F = Poisson, H = Gamma***\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "f(x | \\phi_k) &\\sim Poisson(\\phi_k) \\\\\n",
    "h(\\phi_k) &\\sim Gamma(\\alpha, \\beta) \\\\\n",
    "\\\\\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac{1}{x_{ji}!} \\cdot\n",
    "    \\frac{\\Gamma(x_{ji} + \\alpha_v)}{(1 + \\beta_v)^{x_{ji} + \\alpha_v}} \\cdot\n",
    "    \\frac{(\\beta_v)^{\\alpha_v}}{\\Gamma(\\alpha_v)} \\\\\n",
    "f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) &= \\frac{1}{\\prod_T x_t!} \\cdot\n",
    "    \\frac{\\Gamma(\\sum_T x_t + \\alpha_w)}{(|T| + \\beta_w)^{\\sum_T x_t + \\alpha_w}} \\cdot\n",
    "    \\frac{(\\beta_w)^{\\alpha_w}}{\\Gamma(\\alpha_w)} \\\\\n",
    "\\alpha_v &= \\sum_V x_v + \\alpha \\quad , \\quad \\beta_v = |V| + \\beta \\\\\n",
    "\\alpha_w &= \\sum_W x_w + \\alpha \\quad , \\quad \\beta_w = |W| + \\beta \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "***F = Multinomial, H = Dirichlet***\n",
    "\n",
    "Let $\\mathbf{x}$ be a feature vector of length $L$.  The Multinomial/Dirichlet model is given by\n",
    "$$ \\begin{aligned}\n",
    "f(\\mathbf{x} | n, \\mathbf{\\phi}_k) &\\sim Multinomial(n, \\mathbf{\\phi}_k) \\\\\n",
    "h(\\mathbf{\\phi}_k) &\\sim Dirichlet(L, \\mathbf{\\alpha}) \\\\\n",
    "\\end{aligned} $$\n",
    "Note that each $\\mathbf{x}_{ji}$ can have a different value of $n_{ji}$, representing different size draws from the multinomial distribution.  But $\\phi_k$, representing the relative concentrations of the $L$ components, will be the same.\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "f_k^{-\\mathbf{x}_{ji}}(\\mathbf{x}_{ji}) &= \\frac{n_{ji}!}{\\prod_{\\ell=1}^L (\\mathbf{x}_{ji})_\\ell!} \\cdot\n",
    "    \\frac{ \\prod \\Gamma(\\mathbf{\\alpha}_{\\ell}^{top}) }{ \\Gamma(\\sum \\mathbf{\\alpha}_{\\ell}^{top}) } \\cdot\n",
    "    \\frac{ \\Gamma(\\sum \\mathbf{\\alpha}_{\\ell}^{bottom}) }{ \\prod \\Gamma(\\mathbf{\\alpha}_{\\ell}^{bottom}) } \\\\\n",
    "\\mathbf{\\alpha}_{\\ell}^{bottom} &= \\sum_V (\\mathbf{x}_v)_{\\ell} + \\mathbf{\\alpha}_{\\ell} \\\\\n",
    "\\mathbf{\\alpha}_{\\ell}^{top} &= (\\mathbf{x}_{ji})_{\\ell} + \\mathbf{\\alpha}_{\\ell}^{bottom} \\\\\n",
    "\\\\\n",
    "f_k^{-\\mathbf{X}_{jt}}(\\mathbf{X}_{jt}) &=\n",
    "    \\frac{ \\prod_T n_t! }{ \\prod_T \\prod_{\\ell=1}^L (\\mathbf{x}_t)_\\ell! } \\cdot\n",
    "    \\frac{ \\prod \\Gamma(\\mathbf{\\alpha}_{\\ell}^{top}) }{ \\Gamma(\\sum \\mathbf{\\alpha}_{\\ell}^{top}) } \\cdot\n",
    "    \\frac{ \\Gamma(\\sum \\mathbf{\\alpha}_{\\ell}^{bottom}) }{ \\prod \\Gamma(\\mathbf{\\alpha}_{\\ell}^{bottom}) } \\\\\n",
    "\\mathbf{\\alpha}_{\\ell}^{bottom} &= \\sum_W (\\mathbf{x}_w)_{\\ell} + \\mathbf{\\alpha}_{\\ell} \\\\\n",
    "\\mathbf{\\alpha}_{\\ell}^{top} &= \\sum_T (\\mathbf{x}_t)_\\ell + \\mathbf{\\alpha}_{\\ell}^{bottom} \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "In the application of latent topic modeling for NLP, restaurant $j$ represents document $j$, and customer $ji$ represents some subset of the word counts in document $j$, where $L$ is the size of the entire vocabulary for the corpus of documents.  If a customer is one word, $\\mathbf{x}_{ji}$ is a draw from a categorical distribution of size $L$, a special case of the multinomial; but a customer can also represent the set of all instances of a unique word, the set of words in a sentence, the set of words in a paragraph, etc.\n",
    "\n",
    "The dishes $k$ represent topics (where $\\mathbf{\\phi}_k$ is a distribution over the vocabulary), and the tables $t$ represent clusters of words, sentences, paragraphs (however a \"customer\" is encoded) from a single document.  Due to the nature of the HDP, these topics are shared among documents and among clusters within a document.  If the customer subsets are mutually exclusive, then each section of a document will be assigned to exactly one topic; but if the customers overlap, the same section of a document could be assigned to multiple topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gammaln as logg\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pois_fk_cust(i, x, k, Kmax, ha, hb, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    \n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + ha) - logg(ha) -\n",
    "                         (x[i] + ha)*np.log(1 + hb) + ha*np.log(hb) )\n",
    "    if new == True: return fknew_cust        \n",
    "    \n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers eating kk\n",
    "    xi_in = np.zeros(Kmax)                      # offset if x[i] is in this subset\n",
    "    xi_in[k[i]] = 1\n",
    "      \n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xi_in*x[i] + ha\n",
    "    bv = np.array(list(map(len, x_kks))) - xi_in + hb\n",
    "    fk_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + av) - logg(av) -\n",
    "                      (x[i] + av)*np.log(1 + bv) + av*np.log(bv) )\n",
    "     \n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "def pois_fk_tabl(jj, tt, x, j, t, k, Kmax, ha, hb, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given table across all k values.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    x_jt = x[np.logical_and(j == jj, t == tt)]\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "    \n",
    "    fknew_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + ha) - logg(ha) -\n",
    "                         (np.sum(x_jt) + ha)*np.log(len(x_jt) + hb) + ha*np.log(hb) )\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "    if len(x_jt) == 0:\n",
    "        print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "        new = True\n",
    "    if new == True: return np.full(Kmax, fknew_tabl)\n",
    "    \n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers at tables serving kk\n",
    "    xjt_in = np.zeros(Kmax)                      # offset if table x_jt is in this subset\n",
    "    xjt_in[kk[0]] = 1\n",
    "      \n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xjt_in*np.sum(x_jt) + ha\n",
    "    bv = np.array(list(map(len, x_kks))) - xjt_in*len(x_jt) + hb\n",
    "    fk_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + av) - logg(av) -\n",
    "                       (np.sum(x_jt) + av)*np.log(len(x_jt) + bv) + ha*np.log(bv) )\n",
    "     \n",
    "    return fk_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnom_fk_cust(i, x, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    xi, ni = x[i, :], np.sum(x[i, :])\n",
    "    log_con = logg(ni + 1) - np.sum(logg(xi + 1)) # term constant for all k\n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( log_con + np.sum(logg(xi + ha)) - logg(np.sum(xi + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    if new == True: return fknew_cust        \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]  \n",
    "    \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[k[i], :] -= xi                         # offset if xi is in this subset\n",
    "    a_top = a_bot + xi[None, :]\n",
    "    fk_cust = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "     \n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "def mnom_fk_tabl(jj, tt, x, j, t, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x_jt = x[np.logical_and(j == jj, t == tt), :]                                # (|T|, L)\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "    n_jt = np.sum(x_jt, axis=1)                                                  # (|T|,)\n",
    "    sum_jt = np.sum(x_jt, axis=0)                                                # (L,)\n",
    "    log_con = np.sum(logg(n_jt + 1)) - np.sum(logg(x_jt + 1))    # term constant for all k\n",
    "    \n",
    "    fknew_tabl = np.exp( log_con + np.sum(logg(sum_jt + ha)) - logg(np.sum(sum_jt + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "    if x_jt.shape[0] == 0:\n",
    "        print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "        new = True\n",
    "    if new == True: return fknew_tabl       \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]\n",
    "      \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[kk[0], :] -= sum_jt                       # offset if table x_jt is in this subset\n",
    "    a_top = a_bot + sum_jt[None, :]\n",
    "    fk_tabl = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "\n",
    "    return fk_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDP:\n",
    "    \"\"\"\n",
    "    Model implementing the Chinese Restaurant Franchise Process formulation of the HDP.\n",
    "    \n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - gamma, alpha0: scaling parameters > 0 for base measures H and G0\n",
    "    - f: string representing distribution of data; h is chosen to be conjugate\n",
    "    - hypers: tuple of hyperparameter values specific to f/h scheme chosen\n",
    "    \n",
    "    PRIVATE ATTRIBUTES (volatile)\n",
    "    - tk_map_: (J x Tmax) matrix of k values for each (j,t) pair\n",
    "    - n_: (J x Tmax) matrix specifying counts of customers\n",
    "    - m_: (J x Kmax) matrix specifying counts of tables\n",
    "    - fk_cust_, fk_tabl_: functions to compute mixing components for Gibbs sampling\n",
    "    \n",
    "    PUBLIC ATTRIBUTES\n",
    "    post_samples: (S x 3) matrix of (j, t, k) values for each data point i;\n",
    "                  exists only after gibbs() has been called\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=1, alpha0=1, f='multinomial', hypers=None):\n",
    "        self.g_ = gamma\n",
    "        self.a0_ = alpha0\n",
    "        self.set_priors(f, hypers)\n",
    "        \n",
    "    def set_priors(self, f, hypers):\n",
    "        \"\"\"\n",
    "        Initializes the type of base measure h_ and data-generation function f_.\n",
    "        Also sets hypers_, the relevelant hyperparameters and\n",
    "                  fk_routine_, the function to compute mixing components.\n",
    "        \"\"\"\n",
    "        if f == 'poisson':\n",
    "            # Specify parameters of H ~ Gamma(a,b)\n",
    "            if hypers is None:\n",
    "                self.hypers_ = (1,1)\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_cust_ = pois_fk_cust\n",
    "            self.fk_tabl_ = pois_fk_tabl\n",
    "        \n",
    "        if f == 'multinomial':\n",
    "            if hypers is None:\n",
    "                L = 2\n",
    "                self.hypers_ = (L, np.full(L, 1/L))\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_cust_ = mnom_fk_cust\n",
    "            self.fk_tabl_ = mnom_fk_tabl\n",
    "    \n",
    "    \n",
    "    def tally_up(self, it, which=None):\n",
    "        \"\"\"\n",
    "        Helper function for computing maps and counts in gibbs().\n",
    "        Given a current iteration in the post_samples attribute, does a full\n",
    "        recount of customer/table allocations, updating n_ and m_.\n",
    "        Set which = 'n' or 'm' to only tally up that portion\n",
    "        \"\"\"\n",
    "        \n",
    "        jt_pairs = self.post_samples[it,:,0:2]\n",
    "        \n",
    "        if which != 'm':\n",
    "            # Count customers at each table (jt)\n",
    "            cust_counts = pd.Series(map(tuple, jt_pairs)).value_counts()\n",
    "            j_idx, t_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "            self.n_ *= 0\n",
    "            self.n_[j_idx, t_idx] = cust_counts\n",
    "            \n",
    "        if which != 'n':\n",
    "            # First filter by unique tables (jt), then count tables with each k value\n",
    "            jt_unique, k_idx = np.unique(jt_pairs, axis=0, return_index=True)\n",
    "            jk_pairs = np.c_[self.post_samples[it, k_idx, 0],\n",
    "                             self.post_samples[it, k_idx, 2]]\n",
    "            #print(jk_pairs)\n",
    "            tabl_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "            #print(tabl_counts)\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*tabl_counts.index)))\n",
    "            self.m_ *= 0\n",
    "            self.m_[j_idx, k_idx] = tabl_counts\n",
    "    \n",
    "    \n",
    "    def draw_t(self, it, x, j, Tmax, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        \"\"\"\n",
    "        \n",
    "        t_next, k_next = self.post_samples[it,:,1], self.post_samples[it,:,2]\n",
    "        # Cycle through each t value of each customer, conditioning on everything\n",
    "        # Randomize the order in which updates occur\n",
    "        for i in np.random.permutation(N):\n",
    "            jj, tt0, kk0 = j[i], t_next[i], k_next[i]\n",
    "\n",
    "            # Get vector of customer f_k values (dependent on model specification)\n",
    "            old_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_) \n",
    "            new_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_, new=True) \n",
    "            # Calculate pointwise likelihoods p(x_ji | ...)\n",
    "            M = np.sum(self.m_)\n",
    "            Mk = np.sum(self.m_, axis=0)   # number of tables serving k\n",
    "            lik = old_mixes @ (Mk / (M + self.g_)) + new_mixes * (self.g_ / (M + self.g_))\n",
    "\n",
    "            cust_offset = np.zeros(Tmax)\n",
    "            cust_offset[tt0] = 1\n",
    "            old_t = (self.n_[jj, :] - cust_offset) * old_mixes[self.tk_map_[jj, :]]      \n",
    "            new_t = self.a0_ * lik\n",
    "            # If a table is in use, prob comes from old_t; otherwise, from new_t\n",
    "            t_used = self.n_[jj, :] > 0\n",
    "            t_dist = old_t * t_used.astype('int') + new_t * np.logical_not(t_used).astype('int')\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            t_dist[np.isnan(t_dist)] = 0\n",
    "            t_dist += 1e-6\n",
    "\n",
    "            tt1 = np.random.choice(Tmax, p=t_dist/np.sum(t_dist))\n",
    "            t_next[i] = tt1\n",
    "            self.tally_up(it, which='n')\n",
    "\n",
    "            # If this table was previously unoccupied, we need to select a k\n",
    "            if self.n_[jj, tt1] == 1 and tt0 != tt1:\n",
    "                old_k = np.sum(self.m_, axis=0) * old_mixes\n",
    "                new_k = self.g_ * new_mixes\n",
    "                k_used = np.sum(self.m_, axis=0) > 0\n",
    "                k_dist = old_k * k_used.astype('int') + new_k * np.logical_not(k_used).astype('int')\n",
    "                \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "                   Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "                k_dist[np.isnan(k_dist)] = 0\n",
    "                k_dist += 1e-6\n",
    "\n",
    "                kk1 = np.random.choice(Kmax, p=k_dist/np.sum(k_dist))\n",
    "                self.tk_map_[jj, tt1] = kk1\n",
    "                k_next[i] = self.tk_map_[jj, tt1]\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "            if verbose: print(f\"~ customer (j,i) = {(jj,i)}\" +\n",
    "                              f\" moves table: {tt0} -> {t_next[i]}, k: {kk0} -> {k_next[i]}\")\n",
    "    \n",
    "    \n",
    "    def draw_k(self, it, x, j, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        \"\"\"\n",
    "        \n",
    "        t_next, k_next = self.post_samples[it,:,1], self.post_samples[it,:,2]\n",
    "        # Similarly, cycle through the k values of each table\n",
    "        j_idx, t_idx = np.where(self.n_ > 0)   # find the occupied tables\n",
    "        for i in np.random.permutation(len(j_idx)):\n",
    "            jj, tt = j_idx[i], t_idx[i]\n",
    "            kk0 = self.tk_map_[jj, tt]\n",
    "\n",
    "            # Get vector of table f_k values (dependent on model specification)\n",
    "            old_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_) \n",
    "            new_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_, new=True) \n",
    "\n",
    "            tabl_offset = np.zeros(Kmax)\n",
    "            tabl_offset[kk0] = 1\n",
    "            old_k = (np.sum(self.m_, axis=0) - tabl_offset) * old_mixes\n",
    "            new_k = self.g_ * new_mixes\n",
    "            k_used = np.sum(self.m_, axis=0) > 0\n",
    "            k_dist = old_k * k_used.astype('int') + new_k * np.logical_not(k_used).astype('int')\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            k_dist[np.isnan(k_dist)] = 0\n",
    "            k_dist += 1e-6\n",
    "\n",
    "            #print(f\"{old_k.round(3)}\\n{new_k.round(3)}\\n{k_used}\\n{k_dist.round(3)}\")\n",
    "            kk1 = np.random.choice(Kmax, p=k_dist/np.sum(k_dist))\n",
    "            self.tk_map_[jj, tt] = kk1\n",
    "            k_next[np.logical_and(j == jj, t_next == tt)] = kk1\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "            if verbose: print(f\"~~ table (j,t) = {(jj,tt)} changes dish: {kk0} -> {kk1}\")\n",
    " \n",
    "        \n",
    "    def gibbs(self, x, j, iters, Tmax=5, Kmax=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of t and k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Tmax: maximum number of clusters for each group\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        returns: this CFRP object with post_samples attribute\n",
    "        \"\"\"\n",
    "            \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        # number of tables cannot exceed size of max group\n",
    "        J, N = np.max(j) + 1, len(j)\n",
    "        self.n_ = np.zeros((J, Tmax))\n",
    "        self.m_ = np.zeros((J, Kmax))\n",
    "        self.post_samples = np.zeros((iters+1, N, 3), dtype='int')\n",
    "        self.post_samples[:,:,0] = j\n",
    "        \n",
    "        # Set random initial values for t and k assignments\n",
    "        t0, k0 = self.post_samples[0,:,1], self.post_samples[0,:,2]\n",
    "        t0[:] = np.random.randint(1, Tmax, size=N)\n",
    "        self.tk_map_ = np.random.randint(1, Kmax//2, (J, Tmax))\n",
    "        self.tally_up(it=0, which='n')\n",
    "        for jj in range(J):\n",
    "            for tt in np.where(self.n_[jj, :] > 0)[0]:\n",
    "                #print(f\"mapping: {(jj, tt)} -> {self.tk_map_[jj, tt]}\")\n",
    "                k0[np.logical_and(j == jj, t0 == tt)] = self.tk_map_[jj, tt]\n",
    "        self.tally_up(it=0, which='m')\n",
    "        \n",
    "        for s in range(iters):\n",
    "            if verbose: print(f\"----------------\\n ITERATION {s+1}\\n----------------\")\n",
    "            t_prev, k_prev = self.post_samples[s,:,1], self.post_samples[s,:,2]\n",
    "            t_next, k_next = self.post_samples[s+1,:,1], self.post_samples[s+1,:,2]\n",
    "            # Copy over the previous iteration as a starting point\n",
    "            t_next[:], k_next[:] = t_prev, k_prev\n",
    "            \n",
    "            self.draw_t(s+1, x, j, Tmax, Kmax, verbose)\n",
    "            self.draw_k(s+1, x, j, Kmax, verbose)\n",
    "        \n",
    "        return self  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data (Poisson example)\n",
    "N = 25\n",
    "np.random.seed(0)\n",
    "j = np.random.randint(0, 9, N)\n",
    "x = np.random.poisson(j, N)\n",
    "data = np.c_[x, j]\n",
    "\n",
    "c = HDP(f='poisson', hypers=(1,10)).gibbs(x[:,None], j, iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data (Multinomial example)\n",
    "N, L, Kmax = 200, 100, 10\n",
    "np.random.seed(1)\n",
    "X = np.random.randint(0, 10, (N, L))\n",
    "j = np.random.randint(0, 10, N)\n",
    "\n",
    "c = HDP(f='multinomial', hypers=(L, np.full(L, 1/L))).gibbs(X, j, iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Topic Modeling Application\n",
    "\n",
    "Below is an application of the above sampler using a multinomial data model.  The data is `final_project_data.csv`, produced by the modified preprocessing code in this directory, which contains a `(J, L)` matrix in which entry `(j,l)` contains the count of word `l` in document `j`, with the corresponding words given in the column names.\n",
    "\n",
    "For the Dirichlet prior here, we use the observed distribution of the corpus vocabulary over all documents.  Customers could be encoded in four different ways to compare performance:\n",
    "+ As a single word (such that `f` is categorical)\n",
    "+ As a set of all identical words within a given document (each row of the data matrix has one entry, but the value can vary)\n",
    "+ As a set of all words in a single sentence\n",
    "+ As the entire document (essentially making this a non-hierarchical DP)\n",
    "\n",
    "Since this algorithm has not been optimized, only a subset of the full dataframe is used for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_df = pd.read_csv('final_project_data.csv', index_col=0, dtype='int')\n",
    "vocab = full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_doc(doc_in):\n",
    "    \"\"\"Expands a row (passed in a series) into a dataframe in which each\n",
    "       row contains only the counts of one unique word.\"\"\"\n",
    "    \n",
    "    doc_in = doc_in.iloc[0,:]\n",
    "    words_used = doc1[doc1 > 0]\n",
    "    doc_out = pd.DataFrame(np.zeros((len(words_used), len(vocab)), dtype='int'),\n",
    "                           columns=vocab, dtype='int')\n",
    "    for i, word in enumerate(words_used.index):\n",
    "        doc_out.loc[i, word] = words_used[word]\n",
    "    return doc_out\n",
    "\n",
    "J_ID = 'document#'\n",
    "if J_ID not in full_df.columns:\n",
    "    full_df.insert(0, column=J_ID, value=full_df.index)\n",
    "\n",
    "Jmax = 10\n",
    "wordset_df = full_df.iloc[:Jmax,:].groupby(J_ID).apply(expand_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji_indices = wordset_df.index.to_frame()\n",
    "j = np.array(ji_indices[J_ID])\n",
    "X = np.array(wordset_df)\n",
    "# Get the corresponding word each ji is associated with\n",
    "ji_words = vocab[np.where(X > 0)[1]]\n",
    "\n",
    "Tmax, Kmax = np.max(ji_indices[1]), 20\n",
    "# Get a prior distribution over the vocabulary from selected documents\n",
    "L, h_alpha = X.shape[1], np.sum(X, axis=0)\n",
    "h_alpha = alpha / np.sum(alpha)\n",
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    %time hdp = HDP(f='multinomial', hypers=(L, h_alpha)).gibbs(X, j, 100, Tmax, Kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "k = 0 (size 14)\n",
      "     doc         word  cluster\n",
      "50     1      sterile        0\n",
      "52     1       detect        0\n",
      "56     1  fertilizing        0\n",
      "58     1    mutagenic        0\n",
      "78     2         self        0\n",
      "111    3      isolate        0\n",
      "150    5      elegans        0\n",
      "152    5     nematode        0\n",
      "171    5      isolate        0\n",
      "174    5  application        0\n",
      "277    9  temperature        0\n",
      "282    9       lethal        0\n",
      "290    9      sterile        0\n",
      "299    9     applying        0\n",
      "-----------\n",
      "k = 1 (size 10)\n",
      "     doc            word  cluster\n",
      "62     2        nematode        1\n",
      "67     2     temperature        1\n",
      "93     3       mutations        1\n",
      "94     3         mutants        1\n",
      "101    3      conditions        1\n",
      "117    3         optimal        1\n",
      "165    5       treatment        1\n",
      "215    7        specific        1\n",
      "271    9  caenorhabditis        1\n",
      "298    9       mutagenic        1\n",
      "-----------\n",
      "k = 2 (size 23)\n",
      "     doc         word  cluster\n",
      "13     0   techniques        2\n",
      "21     0      isolate        2\n",
      "34     1      mutants        2\n",
      "48     1         self        2\n",
      "59     1     applying        2\n",
      "116    3  fertilizing        2\n",
      "123    4    mutations        2\n",
      "132    4       lethal        2\n",
      "137    4       series        2\n",
      "141    4      isolate        2\n",
      "145    4    detection        2\n",
      "148    4    mutagenic        2\n",
      "155    5     specific        2\n",
      "156    5        found        2\n",
      "158    5    sensitive        2\n",
      "168    5         self        2\n",
      "186    6        found        2\n",
      "194    6        andor        2\n",
      "210    7      elegans        2\n",
      "216    7        found        2\n",
      "223    7   techniques        2\n",
      "285    9    treatment        2\n",
      "289    9       induce        2\n",
      "-----------\n",
      "k = 3 (size 20)\n",
      "     doc            word  cluster\n",
      "29     0        applying        3\n",
      "45     1       treatment        3\n",
      "80     2         sterile        3\n",
      "91     3  caenorhabditis        3\n",
      "103    3      techniques        3\n",
      "108    3            self        3\n",
      "119    3        applying        3\n",
      "154    5         mutants        3\n",
      "157    5     temperature        3\n",
      "175    5       detection        3\n",
      "202    6          detect        3\n",
      "213    7       mutations        3\n",
      "219    7   hermaphrodite        3\n",
      "226    7       discussed        3\n",
      "236    7     fertilizing        3\n",
      "239    7        applying        3\n",
      "252    8          lethal        3\n",
      "255    8       treatment        3\n",
      "278    9       sensitive        3\n",
      "297    9         optimal        3\n",
      "-----------\n",
      "k = 4 (size 11)\n",
      "     doc           word  cluster\n",
      "4      0        mutants        4\n",
      "9      0  hermaphrodite        4\n",
      "98     3      sensitive        4\n",
      "109    3         induce        4\n",
      "110    3        sterile        4\n",
      "130    4         strain        4\n",
      "143    4       bergerac        4\n",
      "238    7      mutagenic        4\n",
      "272    9       nematode        4\n",
      "291    9        isolate        4\n",
      "296    9    fertilizing        4\n",
      "-----------\n",
      "k = 5 (size 18)\n",
      "     doc           word  cluster\n",
      "2      0       nematode        5\n",
      "17     0         series        5\n",
      "22     0         detect        5\n",
      "33     1      mutations        5\n",
      "42     1         lethal        5\n",
      "69     2  hermaphrodite        5\n",
      "126    4          found        5\n",
      "140    4        sterile        5\n",
      "149    4       applying        5\n",
      "191    6     conditions        5\n",
      "200    6        sterile        5\n",
      "204    6    application        5\n",
      "206    6    fertilizing        5\n",
      "262    8         detect        5\n",
      "264    8    application        5\n",
      "275    9       specific        5\n",
      "279    9  hermaphrodite        5\n",
      "294    9    application        5\n",
      "-----------\n",
      "k = 6 (size 11)\n",
      "     doc            word  cluster\n",
      "1      0  caenorhabditis        6\n",
      "5      0        specific        6\n",
      "15     0       treatment        6\n",
      "28     0       mutagenic        6\n",
      "38     1       sensitive        6\n",
      "86     2     fertilizing        6\n",
      "144    4     application        6\n",
      "250    8          strain        6\n",
      "254    8           andor        6\n",
      "270    9         elegans        6\n",
      "281    9      conditions        6\n",
      "-----------\n",
      "k = 7 (size 20)\n",
      "     doc        word  cluster\n",
      "44     1       andor        7\n",
      "46     1   discussed        7\n",
      "49     1      induce        7\n",
      "53     1    bergerac        7\n",
      "64     2     mutants        7\n",
      "65     2    specific        7\n",
      "68     2   sensitive        7\n",
      "81     2     isolate        7\n",
      "88     2   mutagenic        7\n",
      "128    4   sensitive        7\n",
      "160    5      strain        7\n",
      "163    5  techniques        7\n",
      "178    5   mutagenic        7\n",
      "179    5    applying        7\n",
      "203    6    bergerac        7\n",
      "207    6     optimal        7\n",
      "209    6    applying        7\n",
      "218    7   sensitive        7\n",
      "222    7      lethal        7\n",
      "261    8     isolate        7\n",
      "-----------\n",
      "k = 8 (size 17)\n",
      "     doc            word  cluster\n",
      "10     0          strain        8\n",
      "19     0          induce        8\n",
      "25     0       detection        8\n",
      "120    4         elegans        8\n",
      "127    4     temperature        8\n",
      "176    5     fertilizing        8\n",
      "183    6       mutations        8\n",
      "211    7  caenorhabditis        8\n",
      "231    7         isolate        8\n",
      "233    7        bergerac        8\n",
      "234    7     application        8\n",
      "235    7       detection        8\n",
      "243    8       mutations        8\n",
      "249    8   hermaphrodite        8\n",
      "260    8         sterile        8\n",
      "265    8       detection        8\n",
      "268    8       mutagenic        8\n",
      "-----------\n",
      "k = 9 (size 15)\n",
      "     doc            word  cluster\n",
      "70     2          strain        9\n",
      "84     2     application        9\n",
      "87     2         optimal        9\n",
      "122    4        nematode        9\n",
      "125    4        specific        9\n",
      "131    4      conditions        9\n",
      "139    4          induce        9\n",
      "147    4         optimal        9\n",
      "181    6  caenorhabditis        9\n",
      "185    6        specific        9\n",
      "197    6          series        9\n",
      "208    6       mutagenic        9\n",
      "246    8           found        9\n",
      "258    8            self        9\n",
      "273    9       mutations        9\n",
      "-----------\n",
      "k = 10 (size 19)\n",
      "     doc         word  cluster\n",
      "32     1     nematode       10\n",
      "35     1     specific       10\n",
      "37     1  temperature       10\n",
      "54     1  application       10\n",
      "55     1    detection       10\n",
      "162    5       lethal       10\n",
      "170    5      sterile       10\n",
      "172    5       detect       10\n",
      "187    6  temperature       10\n",
      "192    6       lethal       10\n",
      "193    6   techniques       10\n",
      "198    6         self       10\n",
      "256    8    discussed       10\n",
      "259    8       induce       10\n",
      "274    9      mutants       10\n",
      "276    9        found       10\n",
      "280    9       strain       10\n",
      "284    9        andor       10\n",
      "286    9    discussed       10\n",
      "-----------\n",
      "k = 11 (size 21)\n",
      "     doc        word  cluster\n",
      "0      0     elegans       11\n",
      "6      0       found       11\n",
      "16     0   discussed       11\n",
      "74     2       andor       11\n",
      "92     3    nematode       11\n",
      "95     3    specific       11\n",
      "107    3      series       11\n",
      "113    3    bergerac       11\n",
      "134    4       andor       11\n",
      "135    4   treatment       11\n",
      "164    5       andor       11\n",
      "177    5     optimal       11\n",
      "188    6   sensitive       11\n",
      "195    6   treatment       11\n",
      "201    6     isolate       11\n",
      "212    7    nematode       11\n",
      "228    7        self       11\n",
      "230    7     sterile       11\n",
      "240    8     elegans       11\n",
      "253    8  techniques       11\n",
      "257    8      series       11\n",
      "-----------\n",
      "k = 12 (size 18)\n",
      "     doc            word  cluster\n",
      "24     0     application       12\n",
      "31     1  caenorhabditis       12\n",
      "36     1           found       12\n",
      "39     1   hermaphrodite       12\n",
      "61     2  caenorhabditis       12\n",
      "71     2      conditions       12\n",
      "85     2       detection       12\n",
      "99     3   hermaphrodite       12\n",
      "105    3       treatment       12\n",
      "115    3       detection       12\n",
      "118    3       mutagenic       12\n",
      "217    7     temperature       12\n",
      "220    7          strain       12\n",
      "229    7          induce       12\n",
      "232    7          detect       12\n",
      "267    8         optimal       12\n",
      "269    8        applying       12\n",
      "292    9          detect       12\n",
      "-----------\n",
      "k = 13 (size 10)\n",
      "     doc         word  cluster\n",
      "7      0  temperature       13\n",
      "40     1       strain       13\n",
      "100    3       strain       13\n",
      "106    3    discussed       13\n",
      "112    3       detect       13\n",
      "205    6    detection       13\n",
      "242    8     nematode       13\n",
      "248    8    sensitive       13\n",
      "263    8     bergerac       13\n",
      "295    9    detection       13\n",
      "-----------\n",
      "k = 14 (size 18)\n",
      "     doc           word  cluster\n",
      "3      0      mutations       14\n",
      "8      0      sensitive       14\n",
      "26     0    fertilizing       14\n",
      "47     1         series       14\n",
      "60     2        elegans       14\n",
      "66     2          found       14\n",
      "77     2         series       14\n",
      "82     2         detect       14\n",
      "83     2       bergerac       14\n",
      "90     3        elegans       14\n",
      "96     3          found       14\n",
      "97     3    temperature       14\n",
      "102    3         lethal       14\n",
      "104    3          andor       14\n",
      "114    3    application       14\n",
      "129    4  hermaphrodite       14\n",
      "180    6        elegans       14\n",
      "251    8     conditions       14\n",
      "-----------\n",
      "k = 15 (size 10)\n",
      "     doc         word  cluster\n",
      "20     0      sterile       15\n",
      "30     1      elegans       15\n",
      "57     1      optimal       15\n",
      "167    5       series       15\n",
      "173    5     bergerac       15\n",
      "182    6     nematode       15\n",
      "227    7       series       15\n",
      "247    8  temperature       15\n",
      "288    9         self       15\n",
      "293    9     bergerac       15\n",
      "-----------\n",
      "k = 16 (size 13)\n",
      "     doc            word  cluster\n",
      "14     0           andor       16\n",
      "23     0        bergerac       16\n",
      "41     1      conditions       16\n",
      "153    5       mutations       16\n",
      "161    5      conditions       16\n",
      "166    5       discussed       16\n",
      "169    5          induce       16\n",
      "214    7         mutants       16\n",
      "221    7      conditions       16\n",
      "237    7         optimal       16\n",
      "241    8  caenorhabditis       16\n",
      "245    8        specific       16\n",
      "266    8     fertilizing       16\n",
      "-----------\n",
      "k = 17 (size 16)\n",
      "     doc            word  cluster\n",
      "12     0          lethal       17\n",
      "72     2          lethal       17\n",
      "73     2      techniques       17\n",
      "79     2          induce       17\n",
      "89     2        applying       17\n",
      "136    4       discussed       17\n",
      "146    4     fertilizing       17\n",
      "151    5  caenorhabditis       17\n",
      "159    5   hermaphrodite       17\n",
      "184    6         mutants       17\n",
      "190    6          strain       17\n",
      "196    6       discussed       17\n",
      "199    6          induce       17\n",
      "244    8         mutants       17\n",
      "283    9      techniques       17\n",
      "287    9          series       17\n",
      "-----------\n",
      "k = 18 (size 4)\n",
      "     doc        word  cluster\n",
      "18     0        self       18\n",
      "43     1  techniques       18\n",
      "75     2   treatment       18\n",
      "225    7   treatment       18\n",
      "-----------\n",
      "k = 19 (size 12)\n",
      "     doc            word  cluster\n",
      "11     0      conditions       19\n",
      "27     0         optimal       19\n",
      "51     1         isolate       19\n",
      "63     2       mutations       19\n",
      "76     2       discussed       19\n",
      "121    4  caenorhabditis       19\n",
      "124    4         mutants       19\n",
      "133    4      techniques       19\n",
      "138    4            self       19\n",
      "142    4          detect       19\n",
      "189    6   hermaphrodite       19\n",
      "224    7           andor       19\n"
     ]
    }
   ],
   "source": [
    "# Given seating assignment in final iteration, cluster customers with same k value\n",
    "k_final = hdp.post_samples[-1,:,2]\n",
    "clusters = pd.DataFrame({'doc': j, 'word': ji_words, 'cluster': k_final})\n",
    "for k in set(k_final):\n",
    "    clusters_k = clusters[clusters['cluster'] == k]\n",
    "    print(f\"-----------\\nk = {k} (size {clusters_k.shape[0]})\")\n",
    "    print(clusters_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.3 )* Posterior Sampling by Direct Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
