{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP Gibbs Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.1 )* Posterior Sampling in the Chinese Restaurant Franchise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview\n",
    "\n",
    "The Hierarchical Dirichlet Process mixture model is given by\n",
    "$$\\begin{aligned}\n",
    "G_0 | \\gamma, H &\\sim DP(\\gamma, H) \\\\\n",
    "G_j | \\alpha_0, G_0 &\\sim DP(\\alpha_0, G_0) \\\\\n",
    "\\theta_{ji} | G_j &\\sim G_j \\\\\n",
    "x_{ji} | \\theta_{ji} &\\sim F(\\theta_{ji})\n",
    "\\end{aligned} $$\n",
    "\n",
    "This model is able to non-parametrically cluster each group's data while sharing information both between and within groups.  A Dirichlet process is essentially a discrete distribution with atoms drawn from a (not-necessarily discrete) base measure $H$ and gradually decreasing weights determined by the \"stick-breaking process.\"  In the HDP, each group is a Dirichlet process drawn from another DP $G_0$, so these will contain the same atoms as $G_0$ but with different weights:\n",
    "$$\\begin{aligned}\n",
    "G_0 &= \\sum_{k=1}^{\\infty} \\beta_k \\delta(\\phi_k) \\\\\n",
    "G_j &= \\sum_{k=1}^{\\infty} \\pi_{jk} \\delta(\\phi_k) \\\\\n",
    "\\phi_k | H &\\sim H\n",
    "\\end{aligned} $$\n",
    "Additionally, if we define $\\beta, \\pi_j$ as the collected weights above, it can be shown that these vectors encode a distribution over $\\mathbb{Z}^+$ such that $\\beta | \\gamma \\sim GEM(\\gamma)$ and $\\pi_j | \\alpha_0, \\beta \\sim DP(\\alpha_0, \\beta)$.\n",
    "\n",
    "Successive draws from a DP exhibit clustering behavior, since the probability of taking a certain value is a related to the number of previous draws of that value.  This is shown in the hierarchical sense by the *Chinese restaurant franchise* process.  Imagine a group of Chinese restaurants with a certain number of tables at each restaurant.  Let $\\phi_k$ be the global dishes, drawn from $H$; $\\psi_{jt}$ be the table-specific dishes, drawn from $G_0$; and $\\theta_{ji}$ be the customer-specific dishes, drawn from $G_j$.  Denote $z_{ji}$ as the dish index eaten by customer $ji$; $t_{ji}$ as the table index where customer $ji$ sits; $k_{jt}$ be the dish index served at table $jt$; $n_{jtk}$ be the customer counts; and $m_{jk}$ be the table counts.  Then:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\theta_{ji} | \\text{other } \\theta, \\alpha_0, G_0 &\\sim\n",
    "    \\sum_{t=1}^{m_{j\\cdot}} \\frac{n_{jt\\cdot}}{i-1+\\alpha_0} \\delta(\\psi_{jt}) +\n",
    "                            \\frac{\\alpha_0}{i-1+\\alpha_0} G_0 \\\\\n",
    "\\psi_{jt} | \\text{other } \\psi, \\gamma, H &\\sim\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} \\delta(\\phi_k) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} H\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Conditionals\n",
    "\n",
    "Choose some base measure $h(\\cdot)$ and a conjugate data-generating distribution $f(\\cdot | \\theta)$.  Important to compute are $f_k^{-x_{ji}}(x_{ji})$, the mixture component of customer $ij$ under $k$, and $f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, the mixture component of table $jt$ under $k$.  This is done by integrating out $\\phi_k$ over the joint density of all such points, for example:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac { \\int f(x_{ij} | \\phi_k) g(k)d\\phi_k } { \\int g(k)d\\phi_k } \\\\\n",
    "g(k) &= h(\\phi_k) \\prod_{j'i' \\neq ji, z_{j'i'} = k} f(x_{j'i'} | \\phi_k) \n",
    "\\end{aligned} $$\n",
    "\n",
    "The corresponding mixture components for a new customer assignment and new table assignment are denoted $f_{k^*}^{-x_{ji}}(x_{ji})$ and $f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt})$, which are special cases of their the respective $f_k$ component where no data points have $z_{ij} = k^*$.\n",
    "\n",
    "Using this, we first compute the likelihood of a given point $x_{ji}$ given the current clustering scheme:\n",
    "$$\n",
    "p(x_{ji} | t^{-ji}, t_{ji} = t^*, k) =\n",
    "    \\sum_{k=1}^{K} \\frac{m_{\\cdot k}}{m_{\\cdot k} + \\gamma} f_k^{-x_{ji}}(x_{ji}) +\n",
    "                            \\frac{\\gamma}{m_{\\cdot k} + \\gamma} f_{k^*}^{-x_{ji}}(x_{ji})\n",
    "$$\n",
    "\n",
    "For efficiency, the Gibbs scheme implemented below only samples the $t$ and $k$ indexes (which can later be reverse-engineered to obtain the actual parameters).  The state space of the $k$ values is technically infinite, and the number of tables/dishes currently associated with the data is undefined.  We keep a running list of active $t$ and $k$ values.  Each update step, each customer is assigned either to one of the existing tables or to a new table, and if a customer is assigned to a new table, a new $k$ corresponding value gets drawn; similarly, each table is assigned a dish, either from the existing dishes or with a new dish.  If a table/dish becomes unrepresented in the current scheme, it gets removed from its respective list.  The update full conditionals are:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "p(t_{ji} = t | t^{-ji}, k, ...) &\\propto \\begin{cases}\n",
    "    n_{jt\\cdot}^{-ji} f_{k_{jt}}^{-x_{ji}}(x_{ji}) & t\\text{ used}\\\\\n",
    "    \\alpha_0 p(x_{ji} | ...) & t\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "p(k_{jt} = k | t, k^{-jt}) &\\propto \\begin{cases}\n",
    "    m_{\\cdot k} f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ used}\\\\\n",
    "    \\gamma f_{k^*}^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) & k\\text{ new}\n",
    "    \\end{cases} \\\\\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution-Specific Mixture Components\n",
    "\n",
    "The only part of this sampling algorithm that depends on the choice of the measures $H$ and $F$ are the mixture components $f_k$, so this is the only part that needs rewritten for each type of model.  Let\n",
    "$$ \\begin{aligned}\n",
    "V_{kji} &= \\{ j'i' : j'i' \\neq ji, z_{j'i'} = k \\} \\\\\n",
    "W_{kjt} &= \\{ j'i' : j't_{j'i'} \\neq jt, k_{j't_{j'i'} = k} \\} \\\\\n",
    "T_{jt} &= \\{ j'i': t_{j'i'} = jt \\} \\\\\n",
    "\\end{aligned} $$\n",
    "$V$ is the set of all customers (excluding customer $ij$) eating dish $k$; $W$ is the set of all customers at tables (excluding table $jt$) eating $k$; these correspond to the product terms in the mixture components.  By conjugacy rules and kernel tricks, each $f_k$ can be expressed as functions of these sets.  Each $f_{k^*}$ can be found by using the corresponding $f_k$ formula where $V$ or $W$ is the empty set.\n",
    "\n",
    "*F = Poisson, H = Gamma*\n",
    "$$ \\begin{aligned}\n",
    "f_k^{-x_{ji}}(x_{ji}) &= \\frac{1}{x_{ji}!} \\cdot\n",
    "    \\frac{\\Gamma(x_{ji} + \\alpha_v)}{(1 + \\beta_v)^{x_{ji} + \\alpha_v}} \\cdot\n",
    "    \\frac{(\\beta_v)^{\\alpha_v}}{\\Gamma(\\alpha_v)} \\\\\n",
    "f_k^{-\\mathbf{x}_{jt}}(\\mathbf{x}_{jt}) &= \\frac{1}{\\prod_T x_t!} \\cdot\n",
    "    \\frac{\\Gamma(\\sum_T x_t + \\alpha_w)}{(1 + \\beta_w)^{\\sum_T x_t + \\alpha_w}} \\cdot\n",
    "    \\frac{(\\beta_w)^{\\alpha_w}}{\\Gamma(\\alpha_w)} \\\\\n",
    "\\alpha_v &= \\sum_V x_v + \\alpha \\quad , \\quad \\beta_v = |V| + \\beta \\\\\n",
    "\\alpha_w &= \\sum_W x_w + \\alpha \\quad , \\quad \\beta_w = |W| + \\beta \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "*F = Normal (known variance), H = Normal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import loggamma as logg\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pois_fk(x, t, k, tk, Kmax, ha, hb):\n",
    "    \"\"\"\n",
    "    Computes in one sweep the mixture components for each customer/table for each k.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: fk_cust = (N, Kmax) matrix\n",
    "             fk_tabl = (T, Kmax) matrix\n",
    "             fknew_cust = (N,) vector\n",
    "             fknew_tabl = (T,) vector\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    \n",
    "    fk_cust = np.zeros((len(k), Kmax))\n",
    "    fknew_cust = np.zeros(len(k))\n",
    "    \n",
    "    # FOR k WITH NO MEMBERS\n",
    "    fknew_cust = np.exp( -logg(x + 1) + logg(x + ha) - logg(ha) -\n",
    "                         (x + ha) * np.log(1 + hb) + ha * np.log(hb) )\n",
    "    \n",
    "    # FOR k WITH MEMBERS\n",
    "    for kk in range(Kmax):\n",
    "        x_kk = x[k == kk]               # subset of x values with value kk\n",
    "        x_in = (k == kk).astype('int')  # offset for x values in subset\n",
    "        # If a value for k is not used, same as the prior\n",
    "        if len(x_kk) == 0:\n",
    "            fk_cust[:, kk] = fknew_cust\n",
    "            continue\n",
    "        \n",
    "        # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "        a_denom = (np.sum(x_kk) - x_in*x) + ha\n",
    "        b_denom = (len(x_kk) - x_in) + hb\n",
    "        a_numer = x + a_denom\n",
    "        b_numer = 1 + b_denom\n",
    "        #print(f\"kk = {kk}, subset size = {len(x_kk)}\")\n",
    "        #print(f\"{np.c_[x,k,a_numer,a_denom,b_numer,b_denom]}\")\n",
    "        fk_cust[:, kk] = np.exp( -logg(x + 1) + logg(a_numer) - logg(a_denom) -\n",
    "                                 a_numer * np.log(b_numer) + a_denom * np.log(b_denom) )\n",
    "    \n",
    "    return [fk_cust, fknew_cust]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRP:\n",
    "    \"\"\"\n",
    "    Model implementing the Chinese Franchise Restaurant Process.\n",
    "    \n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - gamma, alpha0: scaling parameters > 0 for base measures H and G0\n",
    "    - f: string representing distribution of data; h is chosen to be conjugate\n",
    "    - hypers: tuple of hyperparameter values specific to f/h scheme chosen\n",
    "    \n",
    "    PRIVATE ATTRIBUTES (volatile)\n",
    "    - t_: set of active t values; formatted as {j: set(t...), ...}\n",
    "    - k_: set of active k values\n",
    "    - tk_map_: (J x Tmax) matrix of k values for each (j,t) pair\n",
    "    - n_: (J x Tmax) matrix specifying counts of customers\n",
    "    - m_: (J x Kmax) matrix specifying counts of tables\n",
    "    - f_, h_: distribution functions\n",
    "    - fk_routine_: a function to compute mixing components for Gibbs sampling\n",
    "    \n",
    "    PUBLIC ATTRIBUTES\n",
    "    post_samples: (S x 4) matrix of (j, t, k, phi) values for each data point i;\n",
    "                  exists only after gibbs() has been called\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=1, alpha0=1, f='poisson', hypers=None):\n",
    "        self.g_ = gamma\n",
    "        self.a0_ = alpha0\n",
    "        self.set_priors(f, hypers)\n",
    "        \n",
    "    def set_priors(self, f, hypers):\n",
    "        \"\"\"\n",
    "        Initializes the type of base measure h_ and data-generation function f_.\n",
    "        Also sets hypers_, the relevelant hyperparameters and\n",
    "                  fk_routine_, the function to compute mixing components.\n",
    "        \"\"\"\n",
    "        if f == 'poisson':\n",
    "            # Specify parameters of H ~ Gamma(a,b)\n",
    "            if hypers is None:\n",
    "                self.hypers_ = (1,1)\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_routine_ = pois_fk\n",
    "    \n",
    "    \n",
    "    def tally_up(self, it, which=None):\n",
    "        \"\"\"\n",
    "        Helper function for computing maps and counts in gibbs().\n",
    "        Given a current iteration in the post_samples attribute, does a full\n",
    "        recount of customer/table allocations, updating n_ and m_.\n",
    "        Set which = 'n' or 'm' to only tally up that portion\n",
    "        \"\"\"\n",
    "        \n",
    "        jt_pairs = self.post_samples[it,:,0:2]\n",
    "        \n",
    "        if which != 'm':\n",
    "            # Count customers at each table (jt)\n",
    "            cust_counts = pd.Series(map(tuple, jt_pairs)).value_counts()\n",
    "            j_idx, t_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "            self.n_[j_idx, t_idx] += cust_counts\n",
    "            \n",
    "        if which != 'n':\n",
    "            # First filter by unique tables (jt), then count tables with each k value\n",
    "            jt_unique, k_idx = np.unique(jt_pairs, axis=0, return_index=True)\n",
    "            jk_pairs = np.c_[self.post_samples[it, k_idx, 0],\n",
    "                             self.post_samples[it, k_idx, 2]]\n",
    "            #print(jk_pairs)\n",
    "            tabl_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "            #print(tabl_counts)\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*tabl_counts.index)))\n",
    "            self.m_[j_idx, k_idx] += tabl_counts\n",
    "    \n",
    "    \n",
    "    def draw_t(self, it, i, Tmax):\n",
    "        \"\"\"\n",
    "        Helper function which draws from the t_ij full conditional.\n",
    "        Returns the drawn t, updates the counts and the samples matrices.\n",
    "        If the drawn t is unused for j, will also draw a k.\n",
    "        \"\"\"\n",
    "        ## CURRENTLY IMPLEMENTED IN GIBBS (TODO?)\n",
    "    \n",
    "    \n",
    "    def draw_k(self, it, i, Tmax):\n",
    "        \"\"\"\n",
    "        Helper function which draws from the k_jt full conditional.\n",
    "        Returns the drawn k, updates the counts and the samples matrices.\n",
    "        \"\"\"\n",
    "        ## CURRENTLY IMPLEMENTED IN GIBBS (TODO?)\n",
    " \n",
    "        \n",
    "    def gibbs(self, x, j, iters=1, Kmax=10):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of t and k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        results: creation of post_samples attribute\n",
    "        \"\"\"\n",
    "            \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        # number of tables cannot exceed size of max group\n",
    "        J, Tmax, N = np.max(j) + 1, np.max(group_counts) + 1, len(j)\n",
    "        self.n_ = np.zeros((J, Tmax))\n",
    "        self.m_ = np.zeros((J, Kmax))\n",
    "        self.post_samples = np.zeros((iters+1, N, 4), dtype='int')\n",
    "        self.post_samples[:,:,0] = j\n",
    "        \n",
    "        # Set random initial values for t and k assignments\n",
    "        t0, k0 = self.post_samples[0,:,1], self.post_samples[0,:,2]\n",
    "        t0[:] = np.random.randint(1, Tmax, size=N)\n",
    "        self.tk_map_ = np.random.randint(1, Kmax//2, (J, Tmax))\n",
    "        self.tally_up(it=0, which='n')\n",
    "        for jj in range(J):\n",
    "            for tt in np.where(self.n_[jj, :] > 0)[0]:\n",
    "                #print(f\"mapping: {(jj, tt)} -> {self.tk_map_[jj, tt]}\")\n",
    "                k0[np.logical_and(j == jj, t0 == tt)] = self.tk_map_[jj, tt]\n",
    "        self.tally_up(it=0, which='m')\n",
    "        \n",
    "        for s in range(iters):\n",
    "            t_prev, k_prev = self.post_samples[s,:,1], self.post_samples[s,:,2]\n",
    "            t_next, k_next = self.post_samples[s+1,:,1], self.post_samples[s+1,:,2]\n",
    "            \n",
    "            # Get matrices of f_k values (dependent on model specification)\n",
    "            mixes = self.fk_routine_(x, t_prev, k_prev, self.tk_map_, Kmax, *self.hypers_) \n",
    "            self.mixes_ = mixes\n",
    "            # Calculate pointwise likelihoods p(x_ji | ...)\n",
    "            Mk = np.sum(self.m_, axis=0)   # number of tables serving k\n",
    "            lik = ( mixes[0] @ (Mk / (Mk + self.g_)) + \n",
    "                    np.tile(mixes[1][:,None], Kmax) @ (self.g_ / (Mk + self.g_)) )\n",
    "            self.lik_ = lik\n",
    "            \n",
    "            t_next = t_prev\n",
    "            # Cycle through each t value of each customer, conditioning on everything\n",
    "            # Randomize the order in which updates occur\n",
    "            print(f\"Tmax = {Tmax}\")\n",
    "            for i in np.random.permutation(N):\n",
    "                jj, tt0 = j[i], t_next[i]\n",
    "                cust_offset = np.zeros(Tmax)\n",
    "                cust_offset[tt0] = 1\n",
    "\n",
    "                old_t = (self.n_[jj, :] - cust_offset) * mixes[0][i, self.tk_map_[jj, :]]      \n",
    "                new_t = self.a0_ * lik[i]\n",
    "                # If a table is in use, prob comes from old_t; otherwise, from new_t\n",
    "                t_used = self.n_[jj, :] > 0\n",
    "                t_dist = old_t * t_used.astype('int') + new_t * np.logical_not(t_used).astype('int')\n",
    "                \n",
    "                tt1 = np.random.choice(Tmax, p=t_dist/np.sum(t_dist))\n",
    "                print(f\"----\\n{(jj,i)} maps {tt0} -> {tt1}:\")\n",
    "                print(f\"{old_t.round(3)}\\n{new_t.round(3)}\\n{t_used}\\n{t_dist.round(3)}\")\n",
    "                t_next[i] = tt1\n",
    "                self.n_[jj, tt0] -= 1\n",
    "                self.n_[jj, tt1] += 1\n",
    "                \n",
    "            k_next = k_prev\n",
    "            # Similarly, cycle through the k values of each table\n",
    "            for i in np.random.permutation(N):\n",
    "                continue            \n",
    "        \n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmax = 6\n",
      "----\n",
      "(5, 8) maps 5 -> 4:\n",
      "[0.    0.    0.071 0.    0.    0.   ]\n",
      "0.098\n",
      "[False False  True False False  True]\n",
      "[0.098 0.098 0.071 0.098 0.098 0.   ]\n",
      "----\n",
      "(8, 15) maps 3 -> 2:\n",
      "[0.    0.003 0.    0.    0.128 0.   ]\n",
      "0.094\n",
      "[False  True False  True  True False]\n",
      "[0.094 0.003 0.094 0.    0.128 0.094]\n",
      "----\n",
      "(8, 4) maps 4 -> 0:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "[False  True  True False  True False]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "----\n",
      "(4, 24) maps 1 -> 0:\n",
      "[0.    0.    0.016 0.016 0.005 0.016]\n",
      "0.019\n",
      "[False  True  True  True  True  True]\n",
      "[0.019 0.    0.016 0.016 0.005 0.016]\n",
      "----\n",
      "(6, 0) maps 3 -> 0:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "[False False  True  True False  True]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "----\n",
      "(4, 22) maps 2 -> 5:\n",
      "[0.001 0.    0.    0.029 0.015 0.029]\n",
      "0.04\n",
      "[ True False  True  True  True  True]\n",
      "[0.001 0.04  0.    0.029 0.015 0.029]\n",
      "----\n",
      "(6, 6) maps 2 -> 4:\n",
      "[0.    0.    0.    0.    0.    0.001]\n",
      "0.002\n",
      "[ True False  True False False  True]\n",
      "[0.    0.002 0.    0.002 0.002 0.001]\n",
      "----\n",
      "(1, 1) maps 5 -> 4:\n",
      "[0.    0.    0.    0.189 0.    0.   ]\n",
      "1.312\n",
      "[False False False  True False  True]\n",
      "[1.312 1.312 1.312 0.189 1.312 0.   ]\n",
      "----\n",
      "(9, 12) maps 2 -> 1:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "[False False  True False  True False]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "----\n",
      "(8, 16) maps 1 -> 4:\n",
      "[0.001 0.    0.001 0.    0.071 0.   ]\n",
      "0.098\n",
      "[ True  True  True False  True False]\n",
      "[0.001 0.    0.001 0.098 0.071 0.098]\n",
      "----\n",
      "(3, 7) maps 3 -> 0:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "1.311\n",
      "[False False False  True False False]\n",
      "[1.311 1.311 1.311 0.    1.311 1.311]\n",
      "----\n",
      "(9, 11) maps 2 -> 3:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "0.002\n",
      "[False  True  True False  True False]\n",
      "[0.002 0.    0.    0.002 0.    0.002]\n",
      "----\n",
      "(1, 23) maps 3 -> 5:\n",
      "[0.    0.    0.    0.    0.064 0.   ]\n",
      "6.689\n",
      "[False False False  True  True False]\n",
      "[6.689 6.689 6.689 0.    0.064 6.689]\n",
      "----\n",
      "(4, 5) maps 4 -> 5:\n",
      "[0.093 0.    0.    0.215 0.    0.43 ]\n",
      "0.524\n",
      "[ True False False  True  True  True]\n",
      "[0.093 0.524 0.524 0.215 0.    0.43 ]\n",
      "----\n",
      "(5, 21) maps 2 -> 1:\n",
      "[0.    0.    0.    0.    0.029 0.   ]\n",
      "0.04\n",
      "[False False  True False  True False]\n",
      "[0.04  0.04  0.    0.04  0.029 0.04 ]\n",
      "----\n",
      "(2, 18) maps 2 -> 5:\n",
      "[0.    0.    0.339 0.    0.    0.   ]\n",
      "1.318\n",
      "[False False  True False False False]\n",
      "[1.318 1.318 0.339 1.318 1.318 1.318]\n",
      "----\n",
      "(4, 2) maps 5 -> 1:\n",
      "[0.093 0.    0.    0.214 0.    0.428]\n",
      "0.524\n",
      "[ True False False  True False  True]\n",
      "[0.093 0.524 0.524 0.214 0.524 0.428]\n",
      "----\n",
      "(8, 9) maps 4 -> 5:\n",
      "[0.    0.    0.    0.    0.012 0.   ]\n",
      "0.015\n",
      "[ True False  True False  True False]\n",
      "[0.    0.015 0.    0.015 0.012 0.015]\n",
      "----\n",
      "(4, 3) maps 3 -> 5:\n",
      "[0.214 0.228 0.    0.    0.    0.378]\n",
      "0.745\n",
      "[ True  True False  True False  True]\n",
      "[0.214 0.228 0.745 0.    0.745 0.378]\n",
      "----\n",
      "(6, 19) maps 5 -> 3:\n",
      "[0.032 0.    0.    0.    0.032 0.   ]\n",
      "0.337\n",
      "[ True False False False  True  True]\n",
      "[0.032 0.337 0.337 0.337 0.032 0.   ]\n",
      "----\n",
      "(9, 17) maps 4 -> 3:\n",
      "[0.    0.001 0.    0.035 0.01  0.   ]\n",
      "0.042\n",
      "[False  True False  True  True False]\n",
      "[0.042 0.001 0.042 0.035 0.01  0.042]\n",
      "----\n",
      "(7, 14) maps 2 -> 5:\n",
      "[0.    0.    0.    0.    0.005 0.   ]\n",
      "0.019\n",
      "[False False  True False  True False]\n",
      "[0.019 0.019 0.    0.019 0.005 0.019]\n",
      "----\n",
      "(9, 20) maps 4 -> 2:\n",
      "[0.    0.012 0.    0.246 0.    0.   ]\n",
      "0.187\n",
      "[False  True False  True  True False]\n",
      "[0.187 0.012 0.187 0.246 0.    0.187]\n",
      "----\n",
      "(7, 10) maps 4 -> 5:\n",
      "[0.    0.    0.    0.    0.    0.035]\n",
      "0.042\n",
      "[False False False False  True  True]\n",
      "[0.042 0.042 0.042 0.042 0.    0.035]\n",
      "----\n",
      "(2, 13) maps 2 -> 3:\n",
      "[0.    0.    0.    0.    0.    0.213]\n",
      "0.513\n",
      "[False False  True False False  True]\n",
      "[0.513 0.513 0.    0.513 0.513 0.213]\n"
     ]
    }
   ],
   "source": [
    "# Simulated data\n",
    "N = 25\n",
    "np.random.seed(0)\n",
    "j = np.random.randint(1, 10, N)\n",
    "x = np.random.poisson(j, N)\n",
    "data = np.c_[x, j]\n",
    "\n",
    "c = CFRP(hypers=(1,10)).gibbs(x[:,None], j)\n",
    "iter0 = c.post_samples[0,:,:]\n",
    "#print(c.fk_)\n",
    "#print(np.c_[c.post_samples[0,:,2], np.argmax(c.fk_, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.2 )* Posterior Sampling with Augmented Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *( 5.3 )* Posterior Sampling by Direct Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
