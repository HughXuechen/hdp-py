{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDP Gibbs Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Samplers\n",
    "\n",
    "Both of the above schemes are implemented in the `HDP` class and callable via the `gibbs_crf` and `gibbs_direct` methods, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gammaln as logg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pois_fk_cust(i, x, k, Kmax, ha, hb, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    \n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + ha) - logg(ha) -\n",
    "                         (x[i] + ha)*np.log(1 + hb) + ha*np.log(hb) )\n",
    "    if new == True: return fknew_cust        \n",
    "    \n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers eating kk\n",
    "    xi_in = np.zeros(Kmax)                      # offset if x[i] is in this subset\n",
    "    xi_in[k[i]] = 1\n",
    "      \n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xi_in*x[i] + ha\n",
    "    bv = np.array(list(map(len, x_kks))) - xi_in + hb\n",
    "    fk_cust = np.exp( -logg(x[i] + 1) + logg(x[i] + av) - logg(av) -\n",
    "                      (x[i] + av)*np.log(1 + bv) + av*np.log(bv) )\n",
    "     \n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "def pois_fk_tabl(jj, tt, x, j, t, k, Kmax, ha, hb, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given table across all k values.\n",
    "    MODEL: base measure H ~ Gamma(ha, hb), F(x|phi) ~ Poisson(phi)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.flatten()  # reshape to 1D, since gibbs routine passes in a 2D array\n",
    "    x_jt = x[np.logical_and(j == jj, t == tt)]\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "    \n",
    "    fknew_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + ha) - logg(ha) -\n",
    "                         (np.sum(x_jt) + ha)*np.log(len(x_jt) + hb) + ha*np.log(hb) )\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "    if len(x_jt) == 0:\n",
    "        print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "        new = True\n",
    "    if new == True: return np.full(Kmax, fknew_tabl)\n",
    "    \n",
    "    x_kks = [x[k == kk] for kk in range(Kmax)]  # subset of customers at tables serving kk\n",
    "    xjt_in = np.zeros(Kmax)                      # offset if table x_jt is in this subset\n",
    "    xjt_in[kk[0]] = 1\n",
    "      \n",
    "    # Compute (a,b) params from gamma kernel tricks done in fk function\n",
    "    av = np.array(list(map(np.sum, x_kks))) - xjt_in*np.sum(x_jt) + ha\n",
    "    bv = np.array(list(map(len, x_kks))) - xjt_in*len(x_jt) + hb\n",
    "    fk_tabl = np.exp( -np.sum(logg(x_jt + 1)) + logg(np.sum(x_jt) + av) - logg(av) -\n",
    "                       (np.sum(x_jt) + av)*np.log(len(x_jt) + bv) + ha*np.log(bv) )\n",
    "     \n",
    "    return fk_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnom_fk_cust(i, x, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    xi, ni = x[i, :], np.sum(x[i, :])\n",
    "    log_con = logg(ni + 1) - np.sum(logg(xi + 1)) # term constant for all k\n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( log_con + np.sum(logg(xi + ha)) - logg(np.sum(xi + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    if new == True: return fknew_cust        \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]  \n",
    "    \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[k[i], :] -= xi                         # offset if xi is in this subset\n",
    "    a_top = a_bot + xi[None, :]\n",
    "    fk_cust = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "     \n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "def mnom_fk_tabl(jj, tt, x, j, t, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Multinomial(n_ji, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x_jt = x[np.logical_and(j == jj, t == tt), :]                                # (|T|, L)\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "    n_jt = np.sum(x_jt, axis=1)                                                  # (|T|,)\n",
    "    sum_jt = np.sum(x_jt, axis=0)                                                # (L,)\n",
    "    log_con = np.sum(logg(n_jt + 1)) - np.sum(logg(x_jt + 1))    # term constant for all k\n",
    "    \n",
    "    fknew_tabl = np.exp( log_con + np.sum(logg(sum_jt + ha)) - logg(np.sum(sum_jt + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "    if x_jt.shape[0] == 0:\n",
    "        print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "        new = True\n",
    "    if new == True: return fknew_tabl       \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]\n",
    "      \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[kk[0], :] -= sum_jt                       # offset if table x_jt is in this subset\n",
    "    a_top = a_bot + sum_jt[None, :]\n",
    "    fk_tabl = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "\n",
    "    return fk_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_fk_cust(i, x, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Categorical(L, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    xi, ni = x[i, :], np.sum(x[i, :])\n",
    "    log_con = logg(ni + 1) - np.sum(logg(xi + 1)) # term constant for all k\n",
    "    # Calculate the case where k has no members\n",
    "    fknew_cust = np.exp( log_con + np.sum(logg(xi + ha)) - logg(np.sum(xi + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    if new == True: return fknew_cust        \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]  \n",
    "    \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[k[i], :] -= xi                         # offset if xi is in this subset\n",
    "    a_top = a_bot + xi[None, :]\n",
    "    fk_cust = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "     \n",
    "    return fk_cust\n",
    "\n",
    "\n",
    "def cat_fk_tabl(jj, tt, x, j, t, k, Kmax, L, ha, new=False):\n",
    "    \"\"\"\n",
    "    Computes the mixture components for a given customer across all k values.\n",
    "    MODEL: base measure H ~ Dirichlet(L, ha_1,...,ha_L),\n",
    "                        F(x|phi) ~ Categorical(L, phi_1,...,phi_L)\n",
    "    All components are calculated exactly in log-space and then exponentiated.\n",
    "    \n",
    "    returns: (Kmax,) vector; if new=True, returns a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    x_jt = x[np.logical_and(j == jj, t == tt), :]                                # (|T|, L)\n",
    "    kk = k[np.logical_and(j == jj, t == tt)]\n",
    "    n_jt = np.sum(x_jt, axis=1)                                                  # (|T|,)\n",
    "    sum_jt = np.sum(x_jt, axis=0)                                                # (L,)\n",
    "    log_con = np.sum(logg(n_jt + 1)) - np.sum(logg(x_jt + 1))    # term constant for all k\n",
    "    \n",
    "    fknew_tabl = np.exp( log_con + np.sum(logg(sum_jt + ha)) - logg(np.sum(sum_jt + ha)) + \n",
    "                         logg(np.sum(ha)) - np.sum(logg(ha)) )\n",
    "    # If table jt doesn't exist, just return the \"new\" mixture component\n",
    "    if x_jt.shape[0] == 0:\n",
    "        print(f\"WARNING: table {(jj, tt)} does not exist currently\")\n",
    "        new = True\n",
    "    if new == True: return fknew_tabl       \n",
    "    \n",
    "    # Get subset of customers eating kk; each entry is a (#, L) matrix\n",
    "    x_kks = [x[k == kk, :] for kk in range(Kmax)]\n",
    "      \n",
    "    # Compute params from Dirichlet kernel tricks done in fk function\n",
    "    a_bot = np.vstack([np.sum(x_kk, axis=0) for x_kk in x_kks]) + ha[None, :]    # (Kmax, L)\n",
    "    a_bot[kk[0], :] -= sum_jt                       # offset if table x_jt is in this subset\n",
    "    a_top = a_bot + sum_jt[None, :]\n",
    "    fk_tabl = np.exp( log_con + np.sum(logg(a_top), axis=1) - logg(np.sum(a_top, axis=1)) +\n",
    "                      logg(np.sum(a_bot, axis=1)) - np.sum(logg(a_bot), axis=1) )\n",
    "\n",
    "    return fk_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StirlingEngine:\n",
    "    \"\"\"\n",
    "    Numerically efficient engine for computing and storing computed Stirling numbers.\n",
    "    \n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - Nmax: largest integer n for which s(n,m) will need to be computed\n",
    "    \n",
    "    PRIVATE ATTRIBUTES\n",
    "    - s_memo_, slog_memo_: running tables of previously computed values\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Nmax):\n",
    "        self.s_memo_ = np.full((Nmax, Nmax), np.nan)\n",
    "        self.slog_memo_ = np.full((Nmax, Nmax), np.nan)\n",
    "        \n",
    "    def stirling(self, n, m):\n",
    "        \"\"\"\n",
    "        Computes an unsigned Stirling number of the first kind.\n",
    "        Uses dynamic programming to store previously computed s(n,m) values,\n",
    "        as this is a repeatedly-called recursive algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        # If this has already been computed, return stored value\n",
    "        if not np.isnan(self.s_memo_[n, m]):\n",
    "            return self.s_memo_[n, m]\n",
    "        else:\n",
    "            return_val = np.nan\n",
    "\n",
    "            # Base cases\n",
    "            if (n == 0 and m == 0) or (n == 1 and m == 1):\n",
    "                return_val = 1\n",
    "            elif (n > 0 and m == 0) or m > n:\n",
    "                return_val = 0\n",
    "            # Recursion relation\n",
    "            else:\n",
    "                return_val = stirling(n-1, m-1) + (n-1)*stirling(n-1, m)\n",
    "\n",
    "            self.s_memo_[n, m] = return_val\n",
    "            return return_val\n",
    "    \n",
    "    \n",
    "    def stirlog(self, n, m):\n",
    "        \"\"\"\n",
    "        Computes the natural logarithm of an unsigned Stirling number,\n",
    "        using the same dynamic programming approach as above.\n",
    "        If s(n,m) = 0, this gets returned as -inf (np.exp(-inf) == 0.0)\n",
    "        \n",
    "        This is the preferred function, as stirling() can encounter overflow errors.\n",
    "        \"\"\"\n",
    "\n",
    "        # If this has already been computed, return stored value\n",
    "        if not np.isnan(self.slog_memo_[n, m]):\n",
    "            return self.slog_memo_[n, m]\n",
    "        else:\n",
    "            return_val = np.nan\n",
    "\n",
    "            # Base cases\n",
    "            if (n == 0 and m == 0) or (n == 1 and m == 1):\n",
    "                return_val = 0\n",
    "            elif (n > 0 and m == 0) or m > n:\n",
    "                return_val = -np.inf\n",
    "            # Recursion relation\n",
    "            else:\n",
    "                log_s1, log_s2 = stirlog(n-1, m-1), stirlog(n-1, m)\n",
    "                # If s1 == 0 (log_s1 == -inf), just return (n-1)*log_s2\n",
    "                # By definition, must have s2 > s1, so only need to check s1\n",
    "                if np.isfinite(log_s1):\n",
    "                    val = (n-1) * np.exp(log_s2 - log_s1)\n",
    "                    # If there is overflow/underflow in `val`, approximate log(1+x) = log(x)\n",
    "                    if np.isfinite(val):\n",
    "                        return_val = log_s1 + np.log1p(val)\n",
    "                    else:\n",
    "                        return_val = log_s2 + np.log(n-1)\n",
    "                else:\n",
    "                    return_val = log_s2 + np.log(n-1)\n",
    "\n",
    "            self.slog_memo_[n, m] = return_val\n",
    "            return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDP:\n",
    "    \"\"\"\n",
    "    Model implementing the Chinese Restaurant Franchise Process formulation of the HDP.\n",
    "    \n",
    "    CONSTRUCTOR PARAMETERS\n",
    "    - gamma, alpha0: scaling parameters > 0 for base measures H and G0\n",
    "    - f: string representing distribution of data; h is chosen to be conjugate\n",
    "    - hypers: tuple of hyperparameter values specific to f/h scheme chosen\n",
    "    \n",
    "    PRIVATE ATTRIBUTES (volatile)\n",
    "    - tk_map_: (J x Tmax) matrix of k values for each (j,t) pair\n",
    "    - beta_: (Kmax + 1,) vector of beta values for each k\n",
    "    - n_: (J x Tmax) matrix specifying counts of customers (gibbs_cfr)\n",
    "    - q_: (J x Kmax) matrix specifying counts of customers (gibbs_direct)\n",
    "    - m_: (J x Kmax) matrix specifying counts of tables\n",
    "    - fk_cust_, fk_tabl_: functions to compute mixing components for Gibbs sampling\n",
    "    - stir_: an object of class StirlingEngine which computes Stirling numbers\n",
    "    \n",
    "    PUBLIC ATTRIBUTES\n",
    "    cfr_samples: (S x 3) matrix of (j, t, k) values for each data point i;\n",
    "                 exists only after gibbs_cfr() has been called\n",
    "    direct_samples: (S x 2) matrix of (j, k) values for each data point i;\n",
    "                    exists only after gibbs_direct() has been called\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=1, alpha0=1, f='multinomial', hypers=None):\n",
    "        self.g_ = gamma\n",
    "        self.a0_ = alpha0\n",
    "        self.set_priors(f, hypers)\n",
    "        \n",
    "    def set_priors(self, f, hypers):\n",
    "        \"\"\"\n",
    "        Initializes the type of base measure h_ and data-generation function f_.\n",
    "        Also sets hypers_, the relevelant hyperparameters and\n",
    "                  fk_routine_, the function to compute mixing components.\n",
    "        \"\"\"\n",
    "        if f == 'poisson':\n",
    "            # Specify parameters of H ~ Gamma(a,b)\n",
    "            if hypers is None:\n",
    "                self.hypers_ = (1,1)\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_cust_ = pois_fk_cust\n",
    "            self.fk_tabl_ = pois_fk_tabl\n",
    "        \n",
    "        elif f == 'multinomial':\n",
    "            if hypers is None:\n",
    "                L = 2\n",
    "                self.hypers_ = (L, np.full(L, 1/L))\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_cust_ = mnom_fk_cust\n",
    "            self.fk_tabl_ = mnom_fk_tabl\n",
    "            \n",
    "        elif f == 'categorical':\n",
    "            # Identical to multinomial, but with some efficiency upgrades\n",
    "            if hypers is None:\n",
    "                L = 2\n",
    "                self.hypers_ = (L, np.full(L, 1/L))\n",
    "            else: self.hypers_ = hypers\n",
    "            self.fk_cust_ = cat_fk_cust\n",
    "            self.fk_tabl_ = cat_fk_tabl\n",
    "    \n",
    "    \n",
    "    def tally_up(self, it, which=None):\n",
    "        \"\"\"\n",
    "        Helper function for computing maps and counts in gibbs().\n",
    "        Given a current iteration in the cfr_samples attribute, does a full\n",
    "        recount of customer/table allocations, updating n_ and m_.\n",
    "        Set which = 'n' or 'm' to only tally up that portion\n",
    "        \"\"\"    \n",
    "        \n",
    "        if which == 'n':\n",
    "            jt_pairs = self.cfr_samples[it,:,0:2]\n",
    "            # Count customers at each table (jt)\n",
    "            cust_counts = pd.Series(map(tuple, jt_pairs)).value_counts()\n",
    "            j_idx, t_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "            self.n_ *= 0\n",
    "            self.n_[j_idx, t_idx] = cust_counts\n",
    "            \n",
    "        elif which == 'm':\n",
    "            jt_pairs = self.cfr_samples[it,:,0:2]\n",
    "            # First filter by unique tables (jt), then count tables with each k value\n",
    "            jt_unique, k_idx = np.unique(jt_pairs, axis=0, return_index=True)\n",
    "            jk_pairs = np.c_[self.cfr_samples[it, k_idx, 0],\n",
    "                             self.cfr_samples[it, k_idx, 2]]\n",
    "            #print(jk_pairs)\n",
    "            tabl_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "            #print(tabl_counts)\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*tabl_counts.index)))\n",
    "            self.m_ *= 0\n",
    "            self.m_[j_idx, k_idx] = tabl_counts\n",
    "            \n",
    "        elif which == 'q':\n",
    "            jk_pairs = self.direct_samples[it,:,:]\n",
    "            # Counts customers at each j eating k\n",
    "            cust_counts = pd.Series(map(tuple, jk_pairs)).value_counts()\n",
    "            j_idx, k_idx = tuple(map(np.array, zip(*cust_counts.index)))\n",
    "            self.q_ *= 0\n",
    "            self.q_[j_idx, k_idx] = cust_counts\n",
    "    \n",
    "    \n",
    "    def draw_t(self, it, x, j, Tmax, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        Called by gibbs_cfr()\n",
    "        \"\"\"\n",
    "        \n",
    "        t_next, k_next = self.cfr_samples[it,:,1], self.cfr_samples[it,:,2]\n",
    "        # Cycle through the t value of each customer, conditioning on everything\n",
    "        # Randomize the order in which updates occur\n",
    "        for i in np.random.permutation(len(j)):\n",
    "            jj, tt0, kk0 = j[i], t_next[i], k_next[i]\n",
    "\n",
    "            # Get vector of customer f_k values (dependent on model specification)\n",
    "            old_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_) \n",
    "            new_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_, new=True) \n",
    "            # Calculate pointwise likelihoods p(x_ji | ...)\n",
    "            M = np.sum(self.m_)\n",
    "            Mk = np.sum(self.m_, axis=0)   # number of tables serving k\n",
    "            lik = old_mixes @ (Mk / (M + self.g_)) + new_mixes * (self.g_ / (M + self.g_))\n",
    "\n",
    "            cust_offset = np.zeros(Tmax)\n",
    "            cust_offset[tt0] = 1\n",
    "            old_t = (self.n_[jj, :] - cust_offset) * old_mixes[self.tk_map_[jj, :]]      \n",
    "            new_t = self.a0_ * lik\n",
    "            # If a table is in use, prob comes from old_t; otherwise, from new_t\n",
    "            t_used = self.n_[jj, :] > 0\n",
    "            t_dist = old_t * t_used.astype('int') + new_t * np.logical_not(t_used).astype('int')\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            t_dist[np.isnan(t_dist)] = 0\n",
    "            t_dist += 1e-6\n",
    "\n",
    "            tt1 = np.random.choice(Tmax, p=t_dist/np.sum(t_dist))\n",
    "            t_next[i] = tt1\n",
    "            self.tally_up(it, which='n')\n",
    "\n",
    "            # If this table was previously unoccupied, we need to select a k\n",
    "            if self.n_[jj, tt1] == 1 and tt0 != tt1:\n",
    "                old_k = np.sum(self.m_, axis=0) * old_mixes\n",
    "                new_k = self.g_ * new_mixes\n",
    "                k_used = np.sum(self.m_, axis=0) > 0\n",
    "                k_dist = old_k * k_used.astype('int') + new_k * np.logical_not(k_used).astype('int')\n",
    "                \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "                   Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "                k_dist[np.isnan(k_dist)] = 0\n",
    "                k_dist += 1e-6\n",
    "\n",
    "                kk1 = np.random.choice(Kmax, p=k_dist/np.sum(k_dist))\n",
    "                self.tk_map_[jj, tt1] = kk1\n",
    "                k_next[i] = self.tk_map_[jj, tt1]\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "            if verbose: print(f\"~ customer (j,i) = {(jj,i)}\" +\n",
    "                              f\" moves table: {tt0} -> {t_next[i]}, k: {kk0} -> {k_next[i]}\")\n",
    "    \n",
    "    \n",
    "    def draw_k(self, it, x, j, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the t_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        Called by gibbs_cfr()\n",
    "        \"\"\"\n",
    "        \n",
    "        t_next, k_next = self.cfr_samples[it,:,1], self.cfr_samples[it,:,2]\n",
    "        # Cycle through the k values of each table\n",
    "        j_idx, t_idx = np.where(self.n_ > 0)   # find the occupied tables\n",
    "        for i in np.random.permutation(len(j_idx)):\n",
    "            jj, tt = j_idx[i], t_idx[i]\n",
    "            kk0 = self.tk_map_[jj, tt]\n",
    "\n",
    "            # Get vector of table f_k values (dependent on model specification)\n",
    "            old_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_) \n",
    "            new_mixes = self.fk_tabl_(jj, tt, x, j, t_next, k_next, Kmax, *self.hypers_, new=True) \n",
    "\n",
    "            tabl_offset = np.zeros(Kmax)\n",
    "            tabl_offset[kk0] = 1\n",
    "            old_k = (np.sum(self.m_, axis=0) - tabl_offset) * old_mixes\n",
    "            new_k = self.g_ * new_mixes\n",
    "            k_used = np.sum(self.m_, axis=0) > 0\n",
    "            k_dist = old_k * k_used.astype('int') + new_k * np.logical_not(k_used).astype('int')\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            k_dist[np.isnan(k_dist)] = 0\n",
    "            k_dist += 1e-6\n",
    "\n",
    "            #print(f\"{old_k.round(3)}\\n{new_k.round(3)}\\n{k_used}\\n{k_dist.round(3)}\")\n",
    "            kk1 = np.random.choice(Kmax, p=k_dist/np.sum(k_dist))\n",
    "            self.tk_map_[jj, tt] = kk1\n",
    "            k_next[np.logical_and(j == jj, t_next == tt)] = kk1\n",
    "            self.tally_up(it, which='m')\n",
    "\n",
    "            if verbose: print(f\"~~ table (j,t) = {(jj,tt)} changes dish: {kk0} -> {kk1}\")\n",
    "    \n",
    "    \n",
    "    def draw_z(self, it, x, j, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the z_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        Called by gibbs_direct()\n",
    "        \"\"\"\n",
    "        \n",
    "        k_next = self.direct_samples[it,:,1]\n",
    "        # Cycle through the k values of each customer\n",
    "        for i in np.random.permutation(len(j)):\n",
    "            jj, kk0 = j[i], k_next[i]\n",
    "            \n",
    "            # Get vector of customer f_k values (dependent on model specification)\n",
    "            old_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_) \n",
    "            new_mixes = self.fk_cust_(i, x, k_next, Kmax, *self.hypers_, new=True) \n",
    "            \n",
    "            cust_offset = np.zeros(Kmax)\n",
    "            cust_offset[kk0] = 1\n",
    "            old_k = (self.q_[jj, :] - cust_offset +\n",
    "                     self.a0_ + self.beta_[:-1]) * old_mixes      \n",
    "            new_k = self.a0_ * self.beta_[-1] * new_mixes\n",
    "            k_used = np.sum(self.m_, axis=0) > 0\n",
    "            k_dist = old_k * k_used + new_k * np.logical_not(k_used)\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            k_dist[np.isnan(k_dist)] = 0\n",
    "            k_dist += 1e-6\n",
    "            \n",
    "\n",
    "            kk1 = np.random.choice(Kmax, p=k_dist/np.sum(k_dist))\n",
    "            k_next[i] = kk1\n",
    "            self.tally_up(it, which='q')\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"~ customer (j,i) = {(jj,i)}\" +\n",
    "                      f\"changes dish: {kk0} -> {kk1}\")\n",
    "                print(f\"  k_dist: {k_dist.round(3)} (sum {np.sum(k_dist)})\")\n",
    "                \n",
    "    \n",
    "    def draw_m(self, it, x, j, Kmax, verbose):\n",
    "        \"\"\"\n",
    "        Helper function which does the draws from the z_ij full conditional.\n",
    "        Updates the counts and the samples matrices at iteration `it`.\n",
    "        Called by gibbs_direct()\n",
    "        \"\"\"\n",
    "        \n",
    "        k_next = self.direct_samples[it,:,1]\n",
    "        self.m_ *= 0                           # reset the m counts\n",
    "        # Cycle through the k values of each restaurant\n",
    "        j_idx, k_idx = np.where(self.q_ > 0)   # find the consumed dishes\n",
    "        for i in np.random.permutation(len(j_idx)):\n",
    "            jj, kk = j_idx[i], k_idx[i]\n",
    "            max_m = self.q_[jj, kk]\n",
    "            \n",
    "            abk = self.a0_ * self.beta_[kk]\n",
    "            m_range = np.arange(max_m) + 1\n",
    "            log_s = np.array([self.stir_.stirlog(max_m, m) for m in m_range])\n",
    "            m_dist = np.exp( logg(abk) - logg(abk + max_m) +\n",
    "                             log_s + m_range * np.log(abk) )\n",
    "            \"\"\"TEMPORARY FIX (bug should be found later):\n",
    "               Remove nans and add epsilon so that distribution is all positive\"\"\"\n",
    "            m_dist[np.isnan(m_dist)] = 0\n",
    "            m_dist += 1e-6\n",
    "            \n",
    "            mm1 = np.random.choice(m_range, p=m_dist/np.sum(m_dist))\n",
    "            self.m_[jj, kk] = mm1\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"~~ restaraunt {jj}: {mm1} tables / {max_m} customers eating {kk}\")\n",
    "                print(f\"m_dist: {m_dist.round(3)}\")\n",
    "                \n",
    "    \n",
    "    def gibbs_cfr(self, x, j, iters, Tmax=5, Kmax=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of t and k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Tmax: maximum number of clusters for each group\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        returns: this HDP object with cfr_samples attribute\n",
    "        \"\"\"\n",
    "            \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        J, N = np.max(j) + 1, len(j)\n",
    "        self.n_ = np.zeros((J, Tmax), dtype='int')\n",
    "        self.m_ = np.zeros((J, Kmax), dtype='int')\n",
    "        self.cfr_samples = np.zeros((iters+1, N, 3), dtype='int')\n",
    "        self.cfr_samples[:,:,0] = j\n",
    "        \n",
    "        # Set random initial values for t and k assignments\n",
    "        t0, k0 = self.cfr_samples[0,:,1], self.cfr_samples[0,:,2]\n",
    "        t0[:] = np.random.randint(0, Tmax, size=N)\n",
    "        self.tk_map_ = np.random.randint(0, Kmax//2, (J, Tmax))\n",
    "        self.tally_up(it=0, which='n')\n",
    "        for jj in range(J):\n",
    "            for tt in np.where(self.n_[jj, :] > 0)[0]:\n",
    "                #print(f\"mapping: {(jj, tt)} -> {self.tk_map_[jj, tt]}\")\n",
    "                k0[np.logical_and(j == jj, t0 == tt)] = self.tk_map_[jj, tt]\n",
    "        self.tally_up(it=0, which='m')\n",
    "        \n",
    "        for s in range(iters):\n",
    "            if verbose: print(f\"----------------\\n ITERATION {s+1}\\n----------------\")\n",
    "            t_prev, k_prev = self.cfr_samples[s,:,1], self.cfr_samples[s,:,2]\n",
    "            t_next, k_next = self.cfr_samples[s+1,:,1], self.cfr_samples[s+1,:,2]\n",
    "            # Copy over the previous iteration as a starting point\n",
    "            t_next[:], k_next[:] = t_prev, k_prev\n",
    "            \n",
    "            self.draw_t(s+1, x, j, Tmax, Kmax, verbose)\n",
    "            self.draw_k(s+1, x, j, Kmax, verbose)\n",
    "        \n",
    "        return self  \n",
    "    \n",
    "    \n",
    "    def gibbs_direct(self, x, j, iters, Kmax=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the Gibbs sampler to generate posterior estimates of k.\n",
    "        x: data matrix, stored row-wise if multidimensional\n",
    "        j: vector of group labels; must have same #rows as x\n",
    "        iters: number of iterations to run\n",
    "        Kmax: maximum number of atoms to draw from base measure H\n",
    "        \n",
    "        returns: this HDP object with direct_samples attribute\n",
    "        \"\"\"\n",
    "        \n",
    "        group_counts = pd.Series(j).value_counts()\n",
    "        J, N = np.max(j) + 1, len(j)\n",
    "        self.q_ = np.zeros((J, Kmax), dtype='int')   # performs the same function as n_\n",
    "        self.m_ = np.zeros((J, Kmax), dtype='int')\n",
    "        self.beta_ = np.ones(Kmax + 1) * (1 / Kmax + 1)\n",
    "        self.direct_samples = np.zeros((iters+1, N, 2), dtype='int')\n",
    "        self.direct_samples[:,:,0] = j\n",
    "        \n",
    "        self.stir_ = StirlingEngine(N)\n",
    "        np.seterr('ignore')\n",
    "        \n",
    "        # Set random initial values for k assignments\n",
    "        k0 = self.direct_samples[0,:,1]\n",
    "        k0[:] = np.random.randint(0, Kmax, size=N)\n",
    "        self.tally_up(it=0, which='q')\n",
    "        # Implicitly set random t assignments by drawing possible m counts (m_jk <= q_jk)\n",
    "        for jj in range(J):\n",
    "            for kk in range(Kmax):\n",
    "                max_m = self.q_[jj, kk]\n",
    "                if max_m == 1:\n",
    "                    self.m_[jj, kk] = 1\n",
    "                elif max_m > 1:\n",
    "                    self.m_[jj, kk] = np.random.randint(1, max_m)\n",
    "        \n",
    "        for s in range(iters):\n",
    "            if verbose: print(f\"----------------\\n ITERATION {s+1}\\n----------------\")\n",
    "            k_prev, k_next = self.direct_samples[s,:,1], self.direct_samples[s+1,:,1]\n",
    "            # Copy over the previous iteration as a starting point\n",
    "            k_next[:] = k_prev\n",
    "            \n",
    "            self.draw_z(s+1, x, j, Kmax, verbose)\n",
    "            self.draw_m(s+1, x, j, Kmax, verbose)\n",
    "            \n",
    "            Mk = np.sum(self.m_, axis=0)\n",
    "            # Dirichlet weights must be > 0, so in case some k is unused, add epsilon\n",
    "            self.beta_ = np.random.dirichlet(np.append(Mk, self.g_) + 1e-6)\n",
    "        \n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "# Simulated data (Poisson example)\n",
    "N = 200\n",
    "np.random.seed(0)\n",
    "j = np.random.randint(0, 9, N)\n",
    "x = np.random.poisson(j, N)\n",
    "data = np.c_[x, j]\n",
    "\n",
    "%time c = HDP(f='poisson', hypers=(1,10)).gibbs_direct(x[:,None], j, iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "# Simulated data (Multinomial example)\n",
    "N, L = 200, 100\n",
    "np.random.seed(1)\n",
    "X = np.random.randint(0, 10, (N, L))\n",
    "j = np.random.randint(0, 10, N)\n",
    "\n",
    "%time c = HDP(f='multinomial', hypers=(L, np.full(L, 1/L))).gibbs_direct(X, j, iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Topic Modeling Application\n",
    "\n",
    "Below is an application of the above sampler using a multinomial data model.  The data is `final_project_data.csv`, produced by the modified preprocessing code in this directory, which contains a `(J, L)` matrix in which entry `(j,l)` contains the count of word `l` in document `j`, with the corresponding words given in the column names.\n",
    "\n",
    "For the Dirichlet prior here, we use the observed distribution of the corpus vocabulary over all documents.  Customers could be encoded in four different ways to compare performance:\n",
    "+ As a single word (such that `f` is categorical)\n",
    "+ As a set of all identical words within a given document (each row of the data matrix has one entry, but the value can vary)\n",
    "+ As a set of all words in a single sentence\n",
    "+ As the entire document (essentially making this a non-hierarchical DP)\n",
    "\n",
    "Since this algorithm has not been optimized, only a subset of the full dataframe is used for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_df = pd.read_csv('final_project_data.csv', index_col=0, dtype='int')\n",
    "vocab = full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_doc(doc_in):\n",
    "    \"\"\"Expands a row (passed in a series) into a dataframe in which each\n",
    "       row contains only the counts of one unique word.\"\"\"\n",
    "    \n",
    "    doc_in = doc_in.drop(J_ID, axis=1)\n",
    "    doc_in = doc_in.iloc[0, :]\n",
    "    words_used = doc_in[doc_in > 0]\n",
    "    doc_out = pd.DataFrame(np.zeros((len(words_used), len(vocab)), dtype='int'),\n",
    "                           columns=vocab, dtype='int')\n",
    "    for i, word in enumerate(words_used.index):\n",
    "        doc_out.loc[i, word] = words_used[word]\n",
    "    return doc_out\n",
    "\n",
    "J_ID = 'document#'\n",
    "if J_ID not in full_df.columns:\n",
    "    full_df.insert(0, column=J_ID, value=full_df.index)\n",
    "\n",
    "Jmax = 10\n",
    "wordset_df = full_df.iloc[:Jmax,:].groupby(J_ID).apply(expand_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji_indices = wordset_df.index.to_frame()\n",
    "j = np.array(ji_indices[J_ID])\n",
    "X = np.array(wordset_df)\n",
    "# Get the corresponding word each ji is associated with\n",
    "ji_words = vocab[np.where(X > 0)[1]]\n",
    "\n",
    "Tmax, Kmax = np.max(ji_indices[1]), 20\n",
    "# Get a prior distribution over the vocabulary from selected documents\n",
    "L, h_alpha = X.shape[1], np.sum(X, axis=0)\n",
    "h_alpha = h_alpha / np.sum(h_alpha)\n",
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 55s\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    %time hdp = HDP(f='multinomial', hypers=(L, h_alpha)).gibbs_direct(X, j, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "k = 0 (size 40)\n",
      "     doc          word  cluster\n",
      "316    7      addition        0\n",
      "251    5        animal        0\n",
      "176    4       animals        0\n",
      "254    5        appear        0\n",
      "234    4     attempted        0\n",
      "444    9    attractive        0\n",
      "384    8       closely        0\n",
      "455    9      colonies        0\n",
      "355    7   consumption        0\n",
      "171    4   development        0\n",
      "417    9       elegans        0\n",
      "166    4       elegans        0\n",
      "66     1      envelope        0\n",
      "84     2         first        0\n",
      "6      0         found        0\n",
      "49     1         gonad        0\n",
      "105    2      granules        0\n",
      "425    9        growth        0\n",
      "194    4    individual        0\n",
      "97     2     localized        0\n",
      "135    3     mechanism        0\n",
      "61     1  mitochondria        0\n",
      "213    4       mitosis        0\n",
      "4      0       mutants        0\n",
      "307    7      nematode        0\n",
      "423    9             p        0\n",
      "125    2   perinuclear        0\n",
      "114    2         place        0\n",
      "193    4     precursor        0\n",
      "454    9     proximity        0\n",
      "281    5       pumping        0\n",
      "392    8     regulator        0\n",
      "331    7     responses        0\n",
      "273    5          self        0\n",
      "188    4           six        0\n",
      "10     0        strain        0\n",
      "65     1       typical        0\n",
      "156    3     typically        0\n",
      "127    2     underwent        0\n",
      "181    4        within        0\n",
      "-----------\n",
      "k = 1 (size 42)\n",
      "     doc          word  cluster\n",
      "395    8          able        1\n",
      "293    5           aid        1\n",
      "112    2        around        1\n",
      "338    7       aspects        1\n",
      "117    2      constant        1\n",
      "410    8   consumption        1\n",
      "186    4     described        1\n",
      "78     1    diakinesis        1\n",
      "310    7     different        1\n",
      "189    4      division        1\n",
      "177    4           dna        1\n",
      "132    3         early        1\n",
      "30     1       elegans        1\n",
      "385    8  experimental        1\n",
      "221    4       failure        1\n",
      "26     0   fertilizing        1\n",
      "366    8      function        1\n",
      "282    5      isolates        1\n",
      "12     0        lethal        1\n",
      "235    4       looking        1\n",
      "53     1          made        1\n",
      "419    9      nematode        1\n",
      "226    4          next        1\n",
      "335    7        oxygen        1\n",
      "164    3        places        1\n",
      "219    4      prophase        1\n",
      "149    3      prophase        1\n",
      "446    9        proved        1\n",
      "326    7  respectively        1\n",
      "210    4          seen        1\n",
      "50     1         shows        1\n",
      "134    3         stage        1\n",
      "191    4       studied        1\n",
      "83     2       studies        1\n",
      "312    7         study        1\n",
      "248    5    suggesting        1\n",
      "159    3  synaptonemal        1\n",
      "7      0   temperature        1\n",
      "405    8    variations        1\n",
      "433    9       various        1\n",
      "128    2      vicinity        1\n",
      "180    4          wild        1\n",
      "-----------\n",
      "k = 2 (size 57)\n",
      "     doc            word  cluster\n",
      "201    4        abnormal        2\n",
      "411    8        accurate        2\n",
      "339    7          adults        2\n",
      "443    9            agar        2\n",
      "240    5            also        2\n",
      "413    8         behaves        2\n",
      "431    9        behavior        2\n",
      "23     0        bergerac        2\n",
      "76     1        branches        2\n",
      "130    3               c        2\n",
      "418    9  caenorhabditis        2\n",
      "1      0  caenorhabditis        2\n",
      "99     2         central        2\n",
      "52     1         central        2\n",
      "337    7          change        2\n",
      "137    3     chromosomes        2\n",
      "278    5        composed        2\n",
      "160    3      diakinesis        2\n",
      "129    3         elegans        2\n",
      "408    8       exception        2\n",
      "332    7         exhibit        2\n",
      "249    5            free        2\n",
      "399    8       generally        2\n",
      "101    2          groups        2\n",
      "138    3      homologous        2\n",
      "123    2           limit        2\n",
      "317    7          living        2\n",
      "380    8             low        2\n",
      "286    5           lumen        2\n",
      "120    2      microscope        2\n",
      "396    8              mm        2\n",
      "271    5      morphology        2\n",
      "382    8            much        2\n",
      "244    5          muscle        2\n",
      "301    5         neurone        2\n",
      "178    4         neurons        2\n",
      "184    4         nuclear        2\n",
      "60     1          oocyte        2\n",
      "95     2         oocytes        2\n",
      "275    5            pair        2\n",
      "70     1          placed        2\n",
      "205    4   postembryonic        2\n",
      "274    5       primarily        2\n",
      "88     2       processes        2\n",
      "437    9    reproduction        2\n",
      "401    8         respect        2\n",
      "8      0       sensitive        2\n",
      "182    4          single        2\n",
      "42     1          single        2\n",
      "421    9         species        2\n",
      "432    9         studied        2\n",
      "372    8           study        2\n",
      "334    7        survival        2\n",
      "259    5        synaptic        2\n",
      "352    7         thermal        2\n",
      "343    7         thought        2\n",
      "173    4            type        2\n",
      "-----------\n",
      "k = 3 (size 47)\n",
      "     doc            word  cluster\n",
      "358    7       anaerobic        3\n",
      "71     1      anatomical        3\n",
      "69     1       apparatus        3\n",
      "29     0        applying        3\n",
      "323    7        behavior        3\n",
      "80     1          bridge        3\n",
      "31     1               c        3\n",
      "168    4  caenorhabditis        3\n",
      "199    4          causes        3\n",
      "383    8        critical        3\n",
      "388    8         current        3\n",
      "359    7     dauerlarvae        3\n",
      "342    7            days        3\n",
      "452    9            dead        3\n",
      "397    8         despite        3\n",
      "147    3      detectable        3\n",
      "85     2           early        3\n",
      "81     2         elegans        3\n",
      "304    7         elegans        3\n",
      "220    4        envelope        3\n",
      "406    8        estimate        3\n",
      "349    7         exposed        3\n",
      "257    5            five        3\n",
      "197    4           forms        3\n",
      "109    2            full        3\n",
      "379    8          higher        3\n",
      "398    8      increasing        3\n",
      "262    5      individual        3\n",
      "19     0          induce        3\n",
      "260    5     information        3\n",
      "345    7          longer        3\n",
      "242    5             may        3\n",
      "140    3         meiotic        3\n",
      "90     2         nuclear        3\n",
      "63     1        numerous        3\n",
      "272    5    observations        3\n",
      "241    5             one        3\n",
      "146    3       oogenesis        3\n",
      "56     1           plays        3\n",
      "102    2         primary        3\n",
      "344    7               q        3\n",
      "232    4        quantity        3\n",
      "38     1          region        3\n",
      "393    8      regulators        3\n",
      "357    7       tolerance        3\n",
      "33     1             two        3\n",
      "375    8             use        3\n",
      "-----------\n",
      "k = 4 (size 46)\n",
      "     doc            word  cluster\n",
      "121    2          always        4\n",
      "285    5         anatomy        4\n",
      "381    8   approximately        4\n",
      "279    5        basement        4\n",
      "306    7  caenorhabditis        4\n",
      "167    4            cell        4\n",
      "320    7         changes        4\n",
      "267    5         classes        4\n",
      "435    9            coli        4\n",
      "75     1          column        4\n",
      "133    3         complex        4\n",
      "327    7      conditions        4\n",
      "292    5    connectivity        4\n",
      "108    2       cytoplasm        4\n",
      "268    5        electron        4\n",
      "340    7   environmental        4\n",
      "265    5      epithelial        4\n",
      "222    4            give        4\n",
      "73     1           golgi        4\n",
      "68     1           great        4\n",
      "187    4              ii        4\n",
      "440    9      increasing        4\n",
      "158    3  interpretation        4\n",
      "185    4           level        4\n",
      "106    2         limited        4\n",
      "183    4          living        4\n",
      "98     2         meiotic        4\n",
      "420    9       nematodes        4\n",
      "302    5  neurosecretory        4\n",
      "111    2         nucleus        4\n",
      "27     0         optimal        4\n",
      "150    3       pachytene        4\n",
      "163    3        persists        4\n",
      "144    3           phase        4\n",
      "228    4           plate        4\n",
      "67     1            pore        4\n",
      "192    4        produced        4\n",
      "37     1            role        4\n",
      "148    3      separation        4\n",
      "255    5             six        4\n",
      "5      0        specific        4\n",
      "313    7           stage        4\n",
      "36     1         suggest        4\n",
      "15     0       treatment        4\n",
      "280    5            unit        4\n",
      "424    9            well        4\n",
      "-----------\n",
      "k = 5 (size 44)\n",
      "     doc           word  cluster\n",
      "223    4     accumulate        5\n",
      "308    7           also        5\n",
      "24     0    application        5\n",
      "300    5      combining        5\n",
      "442    9        contact        5\n",
      "218    4    descendants        5\n",
      "22     0         detect        5\n",
      "124    2     diakinesis        5\n",
      "363    8        elegans        5\n",
      "116    2       exchange        5\n",
      "330    7          forms        5\n",
      "239    5       function        5\n",
      "9      0  hermaphrodite        5\n",
      "314    7      important        5\n",
      "107    2            led        5\n",
      "208    4          light        5\n",
      "356    7          limit        5\n",
      "58     1        limited        5\n",
      "436    9         little        5\n",
      "427    9         living        5\n",
      "403    8       maintain        5\n",
      "299    5       marginal        5\n",
      "43     1       membrane        5\n",
      "370    8          model        5\n",
      "263    5          motor        5\n",
      "3      0      mutations        5\n",
      "131    3       nematode        5\n",
      "77     1          ovary        5\n",
      "104    2          phase        5\n",
      "44     1       presence        5\n",
      "250    5        regions        5\n",
      "387    8       reported        5\n",
      "229    4          round        5\n",
      "18     0           self        5\n",
      "369    8        species        5\n",
      "402    8         stable        5\n",
      "41     1      structure        5\n",
      "74     1          takes        5\n",
      "13     0     techniques        5\n",
      "414    8        tension        5\n",
      "341    7          times        5\n",
      "416    8     undertaken        5\n",
      "245    5           used        5\n",
      "295    5          video        5\n",
      "-----------\n",
      "k = 6 (size 37)\n",
      "     doc            word  cluster\n",
      "322    7          appear        6\n",
      "153    3        believed        6\n",
      "364    8  caenorhabditis        6\n",
      "169    4           cells        6\n",
      "141    3         certain        6\n",
      "161    3         classic        6\n",
      "362    7     deprivation        6\n",
      "227    4          divide        6\n",
      "47     1          double        6\n",
      "236    5         elegans        6\n",
      "438    9         feeding        6\n",
      "264    5            food        6\n",
      "86     2          growth        6\n",
      "266    5             gut        6\n",
      "200    4      hypodermal        6\n",
      "46     1        increase        6\n",
      "89     2           large        6\n",
      "62     1            mass        6\n",
      "297    5     micrographs        6\n",
      "28     0       mutagenic        6\n",
      "365    8        nematode        6\n",
      "170    4        nematode        6\n",
      "270    5         pharynx        6\n",
      "64     1           place        6\n",
      "429    9        presence        6\n",
      "115    2        prophase        6\n",
      "449    9     pseudomonas        6\n",
      "296    5   reconstructed        6\n",
      "441    9          remain        6\n",
      "428    9          showed        6\n",
      "91     2          showed        6\n",
      "20     0         sterile        6\n",
      "162    3        synapsis        6\n",
      "246    5          system        6\n",
      "309    7           three        6\n",
      "126    2            took        6\n",
      "110    2             way        6\n",
      "-----------\n",
      "k = 7 (size 49)\n",
      "     doc            word  cluster\n",
      "328    7         ability        7\n",
      "269    5    accumulation        7\n",
      "14     0           andor        7\n",
      "329    7   approximately        7\n",
      "224    4  asymmetrically        7\n",
      "453    9        bacillus        7\n",
      "415    8          behave        7\n",
      "82     2               c        7\n",
      "407    8        commonly        7\n",
      "11     0      conditions        7\n",
      "79     1        converge        7\n",
      "51     1     cytoplasmic        7\n",
      "253    5       described        7\n",
      "34     1     development        7\n",
      "311    7   developmental        7\n",
      "451    9       dispersal        7\n",
      "209    4         display        7\n",
      "100    2        electron        7\n",
      "439    9     escherichia        7\n",
      "412    8        evaluate        7\n",
      "39     1           first        7\n",
      "151    3  hermaphroditic        7\n",
      "348    7              ie        7\n",
      "394    8       influence        7\n",
      "230    4      interphase        7\n",
      "336    7    investigated        7\n",
      "303    5          lastly        7\n",
      "136    3           least        7\n",
      "298    5          lining        7\n",
      "367    8             may        7\n",
      "247    5        membrane        7\n",
      "2      0        nematode        7\n",
      "172    4             one        7\n",
      "72     1         outside        7\n",
      "96     2            part        7\n",
      "284    5       particles        7\n",
      "165    3         persist        7\n",
      "450    9          plates        7\n",
      "92     2        presence        7\n",
      "430    9            rate        7\n",
      "122    2        remained        7\n",
      "217    4            rise        7\n",
      "321    7       sensitive        7\n",
      "288    5          serial        7\n",
      "179    4           three        7\n",
      "390    8          useful        7\n",
      "103    2           whose        7\n",
      "426    9          within        7\n",
      "207    4           would        7\n",
      "-----------\n",
      "k = 8 (size 42)\n",
      "     doc             word  cluster\n",
      "195    4    approximately        8\n",
      "233    4        breakdown        8\n",
      "212    4  characteristics        8\n",
      "152    3       correspond        8\n",
      "256    5          cuticle        8\n",
      "113    2       detectable        8\n",
      "325    7      differences        8\n",
      "231    4          diploid        8\n",
      "198    4        divisions        8\n",
      "290    5          endings        8\n",
      "354    7            enter        8\n",
      "145    3             even        8\n",
      "190    4             five        8\n",
      "315    7             free        8\n",
      "373    8             free        8\n",
      "291    5            gland        8\n",
      "409    8               hg        8\n",
      "174    4              lin        8\n",
      "196    4         lineages        8\n",
      "94     2     localization        8\n",
      "87     2         membrane        8\n",
      "54     1       microscopy        8\n",
      "203    4       microscopy        8\n",
      "368    8        nematodes        8\n",
      "258    5          nervous        8\n",
      "214    4          nucleus        8\n",
      "143    3     organization        8\n",
      "118    2        pachytene        8\n",
      "157    3           paired        8\n",
      "48     1             part        8\n",
      "154    3           partly        8\n",
      "142    3    recombination        8\n",
      "371    8          related        8\n",
      "294    5             rest        8\n",
      "324    7           stress        8\n",
      "59     1         strongly        8\n",
      "360    7       suggestive        8\n",
      "445    9       supporting        8\n",
      "318    7      temperature        8\n",
      "350    7           values        8\n",
      "202    4          ventral        8\n",
      "155    3            zones        8\n",
      "-----------\n",
      "k = 9 (size 52)\n",
      "     doc            word  cluster\n",
      "447    9      aeruginosa        9\n",
      "448    9      attraction        9\n",
      "434    9        bacteria        9\n",
      "376    8        briggsae        9\n",
      "305    7               c        9\n",
      "237    5  caenorhabditis        9\n",
      "32     1            cell        9\n",
      "238    5           cells        9\n",
      "277    5       contained        9\n",
      "215    4            cord        9\n",
      "25     0       detection        9\n",
      "16     0       discussed        9\n",
      "55     1        electron        9\n",
      "0      0         elegans        9\n",
      "57     1     established        9\n",
      "361    7           harsh        9\n",
      "400    8              ie        9\n",
      "119    2     involvement        9\n",
      "21     0         isolate        9\n",
      "319    7          larval        9\n",
      "333    7            less        9\n",
      "252    5           level        9\n",
      "374    8          living        9\n",
      "283    5          making        9\n",
      "225    4       metaphase        9\n",
      "206    4      morphology        9\n",
      "175    4          mutant        9\n",
      "276    5          nearly        9\n",
      "204    4           nerve        9\n",
      "289    5        neurones        9\n",
      "45     1         oocytes        9\n",
      "386    8          oxygen        9\n",
      "261    5      pharyngeal        9\n",
      "351    7         possess        9\n",
      "216    4      precursors        9\n",
      "40     1         present        9\n",
      "347    7        recovery        9\n",
      "287    5        sections        9\n",
      "17     0          series        9\n",
      "422    9         several        9\n",
      "346    7     specialized        9\n",
      "35     1        specific        9\n",
      "93     2          stages        9\n",
      "377    8         studied        9\n",
      "353    7         survive        9\n",
      "139    3       therefore        9\n",
      "378    8       therefore        9\n",
      "243    5           three        9\n",
      "211    4           times        9\n",
      "389    8            upon        9\n",
      "404    8            view        9\n",
      "391    8           would        9\n"
     ]
    }
   ],
   "source": [
    "# Given seating assignment in final iteration, cluster customers with same k value\n",
    "k_final = hdp.direct_samples[-1,:,1]\n",
    "clusters = pd.DataFrame({'doc': j, 'word': ji_words, 'cluster': k_final})\n",
    "for k in set(k_final):\n",
    "    clusters_k = clusters[clusters['cluster'] == k].sort_values('word')\n",
    "    print(f\"-----------\\nk = {k} (size {clusters_k.shape[0]})\")\n",
    "    print(clusters_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ji_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
