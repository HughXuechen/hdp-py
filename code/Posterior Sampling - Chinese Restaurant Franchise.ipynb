{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Posterior Sampling of Chinese Restaurant Franchise\n",
    "\n",
    "This section contains code for the posterior sampling of our [data](https://web.archive.org/web/20040328153507/http://elegans.swmed.edu/wli/cgcbib) using the algorithm in **Section 5.1** of [Hierarchical Dirichlet Processes](https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I don't understand the posterior sampling for concentration parameters that is in the appendix. How does this tie in?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "import random\n",
    "\n",
    "data = pd.read_csv('final_project_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors on concentration parameters\n",
    "alpha_0 = np.random.gamma(1, 1) \n",
    "gamma_ = np.random.gamma(1, .1) # This prior on gamma always gives us ~ .0001 which leads to random betas ~= .9999. This can't be right... \n",
    "\n",
    "# j is the number of documents\n",
    "j = data.shape[0]\n",
    "\n",
    "# T is truncated on global level\n",
    "T = 100 # arbitrary number\n",
    "\n",
    "# Generate Betas\n",
    "#beta_ = np.random.beta(1, gamma_, T)\n",
    "#BETA = np.zeros(len(beta_))\n",
    "#BETA[0] = beta_[0]\n",
    "#BETA[1:] = beta_[1:]*(1 - beta_[:-1]).cumprod(axis = 0)\n",
    "\n",
    "# Generate Pis\n",
    "#pi_ = np.zeros((j, len(BETA)))\n",
    "#PI = np.zeros((j, len(BETA)))\n",
    "\n",
    "#for k in range(len(BETA)):\n",
    "#    pi_[:,k] = np.random.beta(alpha_0*BETA[k], alpha_0*(1 - sum(BETA[:k+1])), j)\n",
    "\n",
    "#for i in range(j):\n",
    "#    for k in range(len(BETA)):\n",
    "#        PI[i,k] = pi_[i,k]*np.prod(1 - pi_[i,:k])\n",
    "\n",
    "# H is the prior over topic distributions. \n",
    "# We don't know the number of topic distributions so\n",
    "# how do we determine the length of H? Set = to arbitrary T?\n",
    "H = np.zeros((T))\n",
    "prior_H = np.random.beta(1, .5, T)\n",
    "for i in range(T):\n",
    "    H[i] = prior_H[i]*np.prod(1 - prior_H[:i])\n",
    "\n",
    "PHI = H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = data.shape[0]*data.shape[1]\n",
    "table_ = [1]\n",
    "next_table_ = 2\n",
    "\n",
    "\n",
    "num_restaurantJ_tableT = np.zeros((j, T))\n",
    "\n",
    "# This Process is if customers are entering one at a time\n",
    "for i in range(len(data.iloc[0,:]) - 1):\n",
    "    if np.random.rand() < alpha_0/(i + alpha_0):\n",
    "        # Customer i sits at new table\n",
    "        table_.append(next_table_)\n",
    "        next_table_ += 1\n",
    "    else:\n",
    "        choice = np.random.choice(np.array(table_))\n",
    "        table_.append(choice)\n",
    "\n",
    "# We need to consider if people \n",
    "# are already assigned and the N_ij'th person is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling of t\n",
    "\n",
    "**Questions:**\n",
    "-  I'm not sure what $f_{k_{jt}}^{-x_{ji}}(x_{ji})$ is\n",
    "\n",
    "$$\\sum f(x_{ji}\\mid \\phi ) h(\\phi) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3791\n",
       "1    2384\n",
       "3      12\n",
       "4       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign customers to table with probabilty PHI \n",
    "initial_tables = np.random.choice(range(1,101), len(data.iloc[0,:]), p = PHI)\n",
    "pd.Series(initial_tables).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3750\n",
       "1    2423\n",
       "3      13\n",
       "7       1\n",
       "6       1\n",
       "5       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete i-th person and decide their table\n",
    "for i in range(len(initial_tables)):\n",
    "    tmp = list(initial_tables[i+1:]) + list(initial_tables[:i])\n",
    "    \n",
    "    if np.random.rand() < alpha_0 / (len(initial_tables) + alpha_0):\n",
    "        initial_tables = np.insert(tmp, obj = i, values = max(initial_tables) + 1)\n",
    "    else:\n",
    "        choice = np.random.choice(tmp)\n",
    "        initial_tables = np.insert(tmp, obj = i, values = choice)\n",
    "\n",
    "pd.Series(initial_tables).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing each person and choosing $t_i$, the results are nearly identical to the prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Descriptions\n",
    "\n",
    "- **H** - base distribution\n",
    "- **F** - data distribution\n",
    "\n",
    "#### Concentration Parameters:\n",
    "- $\\alpha_0$ - \n",
    "- $\\gamma$ -\n",
    "\n",
    "#### Random Variables\n",
    "- $x_{ji}$ - observed data (arised with draw from distribution $F(\\theta_{ji})$\n",
    "- $\\theta_{ji}$ - customers correspond to the factors $\\theta_{ji}$\n",
    "    - is equal to $\\psi_{jt_{ji}}$\n",
    "- $\\psi_{jt}$ - is the dish served at table $t$ in restaurant $j$\n",
    "    - $\\psi_{jt} = \\phi_{k_{jt}}$\n",
    "    - The table-specific choice of dishes\n",
    "    - is instance of mixture component $k_{jt}$\n",
    "- $\\phi_k$ - the global menu of dishes \n",
    "    - Prior over $\\phi_k$ is $H$\n",
    "    - $K$ iid r.v's\n",
    "- $z_{ji} = k_{jt_{ji}}$ denotes the mixture component associated with the observation $x_{ji}$\n",
    "- $t_{ji}$ - customer $i$ in restaurant $j$ sits at table $t_{ji}$\n",
    "    - The index of the $\\psi_{jt}$ associated with $\\theta_{ji}$\n",
    "- $k_{jt}$ - Table $t$ in restaurant $j$ serves dish $k_{jt}$\n",
    "\n",
    "#### Counts\n",
    "- $n_{jtk}$ - number of customers in restaurant $j$ at table $t$ eating dish $k$\n",
    "- $m_{jk}$ - number of tables in restaurant $j$ serving dish $k$\n",
    "- $K$ - denotes the number of dishes being served throughout the franchise\n",
    "\n",
    "#### Calculation of $p(x_{ji}\\mid \\textbf{t}^{-ji}, t_{ji} = t^{\\text{new}}, \\textbf{k})$\n",
    "\n",
    "............\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change data structure back to way I had it..\n",
    "# in the list of words per document\n",
    "\n",
    "# Also pretty sure I need to change doc.wordIndex to be some global index mapping a value to a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class documentInfo:\n",
    "    def __init__(self, document, docIndex):\n",
    "        self.document = document\n",
    "        self.docIndex = docIndex\n",
    "        self.tableInRestaurantCount = 0\n",
    "        self.docLength = len(document)\n",
    "        self.wordIndex = []\n",
    "        self.tableAssignment = []\n",
    "        self.wordCountByTable = np.zeros(2)\n",
    "        self.tableTopic = np.zeros(2)\n",
    "        \n",
    "        for i in range(self.docLength):\n",
    "            self.wordIndex.append(i)\n",
    "            self.tableAssignment.append(-1)\n",
    "        \n",
    "temp = documentInfo(['the', 'boy', 'jumped', 'over', 'the', 'fence'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialState(documents):\n",
    "    '''Initially assign the words to tables and topics'''\n",
    "    unique_words = set([word for doc in documents for word in doc])\n",
    "    vocabSize = len(unique_words)\n",
    "    wordCount = 0                  # n_{...}\n",
    "    docCount = len(documents)      # Number of Documents\n",
    "    topicCount = 1                 # K\n",
    "    tableCount = 0            # m_{..}\n",
    "    docInfo = []\n",
    "    \n",
    "    for i in range(docCount):\n",
    "        docInfo.append(documentInfo(documents[i], i))\n",
    "        wordCount += len(documents[i])\n",
    "        \n",
    "    p = np.zeros(20)\n",
    "    f = np.zeros(20)\n",
    "    \n",
    "    tableCountByTopic = np.zeros(topicCount + 1)  # m_{.k}\n",
    "    wordCountByTopic = np.zeros(topicCount + 1) # n_{..k}\n",
    "    wordCountByTopicTerm = np.zeros((topicCount + 1, vocabSize)) # n_{word_i, topic k}\n",
    "    \n",
    "    # Assign each topic a single document\n",
    "    for k in range(topicCount):\n",
    "        doc = docInfo[k]\n",
    "        for i in range(doc.docLength):\n",
    "            # Assign each word i in document doc.docIndex to topic k, table 0\n",
    "            assignWord(doc.docIndex, i, 0, k)\n",
    "    \n",
    "    # Randomly assign the remaining documents to topics\n",
    "    for j in range(topicCount, docCount):\n",
    "        doc = docInfo[j]\n",
    "        k = np.random.randint(topicCount) # randomly choose k\n",
    "        for i in range(doc.docLength):\n",
    "            assignWord(doc.docIndex, i, 0, k)\n",
    "                       \n",
    "def assignWord(docIndex, i, table, k):\n",
    "    '''Assign a word to document docIndex, word index i, table table, and topic k'''\n",
    "    doc = docInfo[docIndex]\n",
    "    doc.tableAssignment[i] = table\n",
    "    doc.wordCountByTable[table] += 1\n",
    "    wordCountByTopic[k] += 1\n",
    "    wordCountByTopicTerm[k][doc.wordIndex[i]] += 1\n",
    "    \n",
    "    if (doc.wordCountByTable[table] == 1): # create new table\n",
    "        doc.tableInRestaurantCount += 1\n",
    "        doc.tableTopic[table] = k\n",
    "        tableCount += 1\n",
    "        tableCountByTopic[k] += 1\n",
    "        doc.tableTopic = ENSURECAPACITY(doc.tableTopic, doc.tableInRestaurantCount)\n",
    "        doc.wordCountByTable = ENSURECAPACITY(doc.wordCountByTable, doc.tableInRestaurantCount)\n",
    "        if (k == topicCount):\n",
    "            topicCount += 1\n",
    "            tableCountByTopic = ENSURECAPACITY(tableCountByTopic, topicCount)\n",
    "            wordCountByTopic = ENSURECAPACITY(wordCountByTopic, topicCount)\n",
    "            wordCountByTopicTerm = ADD(wordCountByTopicTerm, np.zeros(vocabSize), topicCount)\n",
    "            \n",
    "def ENSURECAPACITY(input_, min_req = 1):\n",
    "    '''This functions extends the length of array if less than than min_req'''\n",
    "    if (min_req < len(input_)):\n",
    "        return input_\n",
    "    array = np.zeros(2*len(input_))\n",
    "    for i in range(len(input_)):\n",
    "        array[i] = input_[i]\n",
    "    return array\n",
    "    \n",
    "        \n",
    "\n",
    "def ADD(input_, newRow, index_):\n",
    "    '''This function inserts newRow into input_ at index index_'''\n",
    "    if len(input_) <= index_:\n",
    "        tmp = np.zeros((index_*2, len(newRow)))\n",
    "        for i in range(len(input_)):\n",
    "            tmp[i,:] = input_[i,:]\n",
    "        input_ = tmp\n",
    "    input_[index,:] = newRow\n",
    "    return input_\n",
    "\n",
    "def updateK():\n",
    "    '''Sample a new topic K from full conditional'''\n",
    "    p = ENSURECAPACITY(p, topicCount)\n",
    "    pSum = 0\n",
    "    for k in range(topicCount):\n",
    "        pSum += tableCountByTopic[k] * f[k]\n",
    "        p[k] = pSum\n",
    "    \n",
    "    pSum += gamma/ vocabSize\n",
    "    p[topicCount] = pSum\n",
    "    \n",
    "    rand_draw = np.random.rand()*pSum\n",
    "    for k in range(topicCount):\n",
    "        if rand_draw < p[k]:\n",
    "            newTopic = k\n",
    "            break\n",
    "    return newTopic\n",
    "\n",
    "def updateT(docIndex, i):\n",
    "    '''Sample a new table T from full conditional for customer i in restaurant docIndex'''\n",
    "    doc = docInfo[docIndex]\n",
    "    f = ENSURECAPACITY(f, topicCount)\n",
    "    p = ENSURECAPACITY(p, topicCount)\n",
    "    fNew = gamma / vocabSize # right side of equation 31 (although i dont see how vocabSize comes into play)\n",
    "    for k in range(topicCount):\n",
    "        f[k] = (wordCountTopicTerm[k, doc.wordIndex[i]] + beta) / (wordCountByTopic[k] + vocabSize*beta)  # I have 0 intuition to what role beta and vb and even vocabSize have in the equations\n",
    "        fNew += tableCountByTopic[k] * f[k] # left side of equation 31\n",
    "    for j in range(doc.tableInRestaurantCount):\n",
    "        if doc.wordCountByTable[j] > 0:\n",
    "            pSum += doc.wordCountByTable[j] * f[doc.tableTopic[j]] # top of equation 32\n",
    "        p[j] = pSum\n",
    "    \n",
    "    pSum += alpha_0 * fNew/(tableCount + gamma) # bottom of 32 and division in 31\n",
    "    p[doc.tableInRestaurantCount] = pSum\n",
    "    rand_draw = np.random.rand()*pSum\n",
    "    for j in range(doc.numberInRestaurantCount):\n",
    "        if(rand_draw < p[j]):\n",
    "            table_choice = j\n",
    "            break\n",
    "            \n",
    "    return table_choice\n",
    "\n",
    "def removeWord(docIndex, i):\n",
    "    '''Remove word from document[docIndex] and wordIndex[i]'''\n",
    "    doc = docInfo[docIndex]\n",
    "    table = doc.tableAssignment[i] # the table where word i is sitting\n",
    "    k = doc.tableTopic[table] # the topic at table word i is sitting\n",
    "    doc.wordCountByTable -= 1\n",
    "    wordCountByTopic[k] -= 1\n",
    "    wordCountByTopicTerm[k][doc.wordIndex[i]] -= 1\n",
    "    if doc.wordCountByTable[table] == 0: # remove table if no one at it\n",
    "        tableCount -= 1\n",
    "        tableCountByTopic[k] -= 1\n",
    "        doc.tableTopic[table] = -1 # They have -- but subtracting 1 from a topic just changes the topic...\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.997176611775973"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(([3,3,3,3,3,], [2,2,2,2,2], [4,4,4,4,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE ADD (LINE 55) FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 0\n",
    "for i in range(10):\n",
    "    g += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected value of dirichlet\n",
    "def dirichlet_EV(alpha):\n",
    "    if (len(alpha.shape) == 1):\n",
    "        return(sp.psi(alpha)- sp.psi(np.sum(alpha)))\n",
    "    \n",
    "    return(sp.psi(alpha) - sp.psi(np.sum(alpha, 1))[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_0 | gamma_, H ~ DP(gamma_, H)\n",
    "\n",
    "#G_j | alpha_0, G_0 ~ DP(alpha_0, G_0)\n",
    "\n",
    "#theta_ji | G_j ~ G_j\n",
    "\n",
    "#x_ji | theta_ji ~ F(theta_ji)\n",
    "\n",
    "#G_0 = sum(beta_k * delta_phi_k)\n",
    "#G_j = sum(pi_jk * delta_phi_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
